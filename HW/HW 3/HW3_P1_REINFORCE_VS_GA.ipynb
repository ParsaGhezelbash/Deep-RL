{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qm_04eLVkW2"
      },
      "source": [
        "# Run this Notebook\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DeepRLCourse/Homework-3-Questions/blob/main/HW3_P1_REINFORCE_VS_GA.ipynb)  \n",
        "[![Open in Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/DeepRLCourse/Homework-3-Questions/blob/main/HW3_P1_REINFORCE_VS_GA.ipynb)\n",
        "\n",
        "# HW3: REINFORCE Vs. GA\n",
        "> - Full Name: **Parsa Ghezelbash**\n",
        "> - Student ID: **401110437**\n",
        "\n",
        "\n",
        "This notebook implements a Grid World environment where an agent learns to navigate from a start position to a goal while avoiding penalties. It compares two learning approaches:\n",
        "\n",
        "1. REINFORCE Algorithm (Policy Gradient)\n",
        "2. Genetic Algorithm\n",
        "\n",
        "Follow the instructions in each section to complete the homework.\n",
        "\n",
        "**Grading Breakdown:**\n",
        "\n",
        "- Practical Implementation: 60 points\n",
        "- Conceptual Understanding: 40 points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIV1aBVOVkW3"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3E7ds6pVkW3"
      },
      "source": [
        "All required packages are pre-installed if using Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zIoHwp7VkW3"
      },
      "source": [
        "Import the following libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPTr6YAZVkW3",
        "outputId": "1107128c-db21-45cf-d7a0-ecb383478a8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npDihcn-VkW4"
      },
      "source": [
        "# Environment (10 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VIbPrUNVkW4"
      },
      "source": [
        "### GridWorld Class Definition (10 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gzZ21DR3VkW4"
      },
      "outputs": [],
      "source": [
        "# Grid World Parameters\n",
        "GRID_SIZE = 7\n",
        "\n",
        "PENALTIES = {\n",
        "    (0, 3): -50,\n",
        "    (1, 0): -50,\n",
        "    (2, 1): -50,\n",
        "    (3, 3): -50,\n",
        "    (4, 2): -50,\n",
        "    (5, 5): -50,\n",
        "    (0, 4): -50,\n",
        "    (6, 3): -50\n",
        "}\n",
        "\n",
        "GOAL = (6, 6)\n",
        "\n",
        "GOAL_REWARD = 100\n",
        "STEP_PENALTY = -5\n",
        "BOUNDARY_PENALTY = -1\n",
        "\n",
        "ACTIONS = ['up', 'down', 'left', 'right']\n",
        "ACTION_IDX = {a: i for i, a in enumerate(ACTIONS)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdM2t2xbVkW4"
      },
      "source": [
        "### GridWorld Environmnet Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jQCWrZErVkW4"
      },
      "outputs": [],
      "source": [
        "class GridWorld:\n",
        "    def step(self, state, action):\n",
        "        x, y = state\n",
        "        new_x, new_y = x, y\n",
        "\n",
        "        if action == 'right':\n",
        "            new_x = min(x + 1, GRID_SIZE - 1)\n",
        "        elif action == 'left':\n",
        "            new_x = max(x - 1, 0)\n",
        "        elif action == 'up':\n",
        "            new_y = min(y + 1, GRID_SIZE - 1)\n",
        "        elif action == 'down':\n",
        "            new_y = max(y - 1, 0)\n",
        "\n",
        "        reward = STEP_PENALTY\n",
        "        if (new_x, new_y) == (x, y):\n",
        "            reward += BOUNDARY_PENALTY\n",
        "        if (new_x, new_y) in PENALTIES:\n",
        "            reward += PENALTIES[(new_x, new_y)]\n",
        "        if (new_x, new_y) == GOAL:\n",
        "            reward += GOAL_REWARD\n",
        "\n",
        "        return (new_x, new_y), reward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nurQzzl_VkW5"
      },
      "source": [
        "### Initialize the Grid World"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fU3GAx06VkW5"
      },
      "outputs": [],
      "source": [
        "grid_world = GridWorld()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Djg0CI67VkW5"
      },
      "source": [
        "### Plot Empty Grid World"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "TxqhAyerVkW5",
        "outputId": "d1ec4b03-326d-48f4-a082-18c6307daab1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaoAAAHDCAYAAAB1dF5kAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAANbpJREFUeJzt3Xl0VPX9//HXJJkMWQFlSzCEfSdRGklZBKoJi34RbK1WoGyiR5qAypdfW3pOK+kitscqCopQC/YL31S7CForSESBArIXiy0FwSBUWYSvJJBAMiT398cwY0ISyISZzGduno9zciZ3f39mLrxy7/3MvQ7LsiwBAGCoiFAXAADA1RBUAACjEVQAAKMRVAAAoxFUAACjEVQAAKMRVAAAoxFUAACjEVQAAKMRVEAdpkyZoo4dO15zviNHjsjhcOiVV14Jek3Xa/jw4Ro+fPg159uwYYMcDoc2bNgQ9JqAayGoYDuFhYXKzc1V9+7dFRsbq9jYWPXu3Vs5OTn6xz/+EZKaduzYIYfDoWeffbbGtLFjx8rhcGj58uU1pg0dOlTt27dvjBIBYxFUsJW33npLffv21YoVK5SVlaVnn31Wzz33nEaPHq23335bN998sz799NN6res3v/mNDhw4EJC6+vfvr9jYWG3evLnGtK1btyoqKkpbtmypNr68vFw7d+7U4MGDA1IDEK6iQl0AECiHDx/Wd77zHaWmpmr9+vVKSkqqNv2Xv/ylXnzxRUVEXP3vs5KSEsXFxcnpdAastqioKGVmZtYIowMHDuj06dMaP358jRDbvXu3Ll68qCFDhlz39ktLSxUbG3vd6wFCgSMq2MavfvUrlZSUaPny5TVCSvKExaxZs5SSkuIbN2XKFMXHx+vw4cO68847lZCQoAkTJvimXXmN6uzZs5oyZYqaN2+uFi1aaPLkyTp79my96hsyZIhOnjypQ4cO+cZt2bJFiYmJevjhh32hVXWadzmvF198UX369JHL5VJycrJycnJqbH/48OHq27evdu/eraFDhyo2NlY/+tGP6qzrP//5j8aNG6e4uDi1adNGjz/+uMrKyurVJqAxcEQF23jrrbfUtWtXZWZm+rXcpUuXNHLkSA0ZMkRPP/10nUcelmVp7Nix2rx5sx555BH16tVLq1at0uTJk+u1HW/gbN68WV27dpXkCaOvf/3ryszMlNPp1NatW3X33Xf7piUkJCg9PV2SNG/ePOXl5SkrK0szZszQgQMHtHjxYu3cuVNbtmypdgR45swZjR49Wt/5znc0ceJEtW3bttaaLly4oDvuuENHjx7VrFmzlJycrBUrVui9996r35sHNAYLsIGioiJLkjVu3Lga07788kvriy++8P2Ulpb6pk2ePNmSZP3whz+ssdzkyZOt1NRU3/Dq1astSdavfvUr37hLly5Zt912myXJWr58+VVrLC4utiIjI60HH3zQN65Hjx5WXl6eZVmWNWDAAOv//b//55vWunVrKzs727Isyzp16pQVHR1tjRgxwqqoqPDNs2jRIkuStWzZMt+4YcOGWZKsl156qUYNw4YNs4YNG+YbXrBggSXJ+sMf/uAbV1JSYnXt2tWSZL3//vtXbRPQGDj1B1soLi6WJMXHx9eYNnz4cLVu3dr388ILL9SYZ8aMGdfcxttvv62oqKhq80ZGRmrmzJn1qjEhIUFpaWm+a1GnT5/WgQMHNGjQIEnS4MGDfaf7Dh48qC+++MJ3FPbuu++qvLxcjz32WLVrbA899JASExP117/+tdq2XC6Xpk6dWq82JSUl6d577/WNi42N1cMPP1yvNgGNgaCCLSQkJEiSzp8/X2PakiVLVFBQoJUrV9a6bFRUlG666aZrbuPTTz9VUlJSjTDs0aNHvescMmSI71rU1q1bFRkZqa9//euSpEGDBmn37t0qKyurcX3K21Pxym1FR0erc+fONXoytm/fXtHR0fVqU9euXeVwOBrcJiDYCCrYQvPmzZWUlKSPPvqoxrTMzExlZWXV2c3b5XJdsydgoHiDZ8uWLdqyZYv69evnC75BgwaprKxMO3fu1ObNmxUVFeULMX/FxMQErGYg1Agq2MZdd92lQ4cOaceOHUFZf2pqqo4fP17jqM2f71pV7VCxZcuWauGZnJys1NRUX4jdcsstvo4dqamptW6rvLxchYWFvukNadPhw4dlWVaD2wQEG0EF2/j+97+v2NhYTZs2TSdPnqwx/cr/jP1155136tKlS1q8eLFvXEVFhRYuXFjvdSQnJ6tTp05av369du3a5bs+5TVo0CCtXr1aBw4cqNYtPSsrS9HR0Xr++eerteO3v/2tioqKdNdddzW4TZ9//rn+9Kc/+caVlpZq6dKlDVofEAx0T4dtdOvWTfn5+XrggQfUo0cPTZgwQenp6bIsS4WFhcrPz1dERES9rkfVZsyYMRo8eLB++MMf6siRI+rdu7def/11FRUV+bWeIUOGaMWKFZJU43TkoEGD9Pvf/943n1fr1q01d+5c5eXladSoUbr77rt14MABvfjii7r11ls1ceLEBrXpoYce0qJFizRp0iTt3r1bSUlJWrFiBV8OhllC2+kQCLxDhw5ZM2bMsLp27Wo1a9bMiomJsXr27Gk98sgj1t69e6vNO3nyZCsuLq7W9VzZPd2yLOvMmTPWd7/7XSsxMdFq3ry59d3vftf6+9//Xq/u6V5LliyxJFnt27evMW3Pnj2WJEuSdfLkyRrTFy1aZPXs2dNyOp1W27ZtrRkzZlhffvlltXmGDRtm9enTp9ZtX9k93bIs69NPP7XuvvtuKzY21mrVqpX16KOPWmvXrqV7OozhsKzrPB8CAEAQcY0KAGA0ggoAYDSCCgBgNIIKAGA0ggoAYDSCCgBgtEb/wm9lZaU+//xzJSQk1LgRJgCgabAsS+fOnVNycvI177XZ6EH1+eefV3vCKgCg6Tp27Ng17xbT6EHlfRzDsWPHlJiY2KB1uN1urVu3TiNGjKj2VFM7oq3201TaKdFWOwpUO4uLi5WSkuLLhKtp9KDynu5LTEy8rqCKjY1VYmKirXcIibbaUVNpp0Rb7SjQ7azPJSA6UwAAjEZQAQCMRlABAIxm5POoKisrVV5eXud0t9utqKgoXbx4URUVFY1YWeMLZVudTqciIyMbdZsAcCXjgsr7aO3Kyso657EsS+3atdOxY8ds/12sULe1RYsWateune3fZwDmMiqoLMvS8ePHFRkZqZSUlDq/BFZZWanz588rPj7+ml8UC3ehaqtlWSotLdWpU6ckSUlJSY22bQCoyqigunTpkkpLS5WcnHzVR2F7Tw02a9asSQRVqNoaExMjSTp16pTatGnDaUAAIWHU//LeazDR0dEhrgRe3j8Y3G53iCsB0FQZFVReXA8xB58FgFAzMqgAAPDyO6g+++wzTZw4UTfeeKNiYmLUr18/7dq1Kxi1AQBMUVYmvf++ZFmeYcvyDJeVBX3TfgXVl19+qcGDB8vpdGrNmjX617/+pV//+tdq2bJlsOoLG1988YVmzJihDh06yOVyqV27dho5cqS2bNkiyXMKbfXq1QHZ1pEjR+RwOLR3796ArA8ArqqsTBo3Trr9dmnuXM+4H/7QMzxuXNDDyq9ef7/85S+VkpKi5cuX+8Z16tQp4EU11MdnPta58nN1Tk+ITlC3G7sFZdvf+ta3VF5ert/97nfq3LmzTp48qfXr1+vMmTMB3c7VvggNAAHnDal16zzDixdLQ4dKL73kGV63zjN99WrJ5QpKCX4F1ZtvvqmRI0fq29/+tjZu3Kj27dvre9/7nh566KGgFOePj898rO6Lul9zvoO5BwMeVmfPntXf/vY3bdiwQcOGDZMkpaamasCAAZKkjh07SpLuuece37QjR47o8OHDmj17trZt26aSkhL16tVL8+fPV1ZWlm/dnTt31oQJE3T06FG98cYb+uY3v6nf/e53kqRbbrlFkjRs2DBt2LAhoG0CAEnS1q3S2rV1T6+s9Ez/4ANp+PCglOBXUH3yySdavHixZs+erR/96EfauXOnZs2apejoaE2ePLnWZcrKylRW5bCwuLhYkqe785Vdnt1utyzLUmVl5TXvTOF99c5XdLGoXm0oulh01XU3RGxsrOLj47Vq1SoNGDBAriv+qti+fbvatWun3/72txo1apQiIyNVWVmp4uJijRo1Sj/72c/kcrm0YsUKjRkzRvv371eHDh18yy9cuFA//vGP9ZOf/ESSNGPGDH3961/XunXr1KdPH0VHRwe8TV6VlZWyLEtutzvo36Py7g927wrfVNop0VZbGDxYevxx3xGU+/L3K72vkqQZM6RBgyQ/2u7P++SwvP/r10N0dLQyMjK0detW37hZs2Zp586d+uCDD2pdZt68ecrLy6sxPj8/v8aXeqOiotSuXTulpKT4/V2qD099qOG/H37N+TY8sEHpbdL9Wnd9vPnmm3r00Ud18eJFpaWlafDgwfrmN7+pvn37SpJatmyplStX6q677rrqegYOHKipU6fq4YcfliSlpaUpLS1NK1eu9M1z9OhRpaena9OmTerXr1/A21JVeXm5jh07phMnTujSpUtB3RaApqO0tFTjx49XUVHRNZ9N6NcRVVJSknr37l1tXK9evfTnP/+5zmXmzp2r2bNn+4a9T3UcMWJEjeIuXryoY8eOKT4+Xs2aNatznZZl6dy5c0pISPB9zyeuJK5ebYiLi2vwAxuvZuLEibr33nv1t7/9Tdu3b9fatWv1/PPPa+nSpZoyZYokz50eqm77/PnzysvL09tvv63jx4/r0qVLunDhgr744gvffBEREbr55purtTU+Pj6obanq4sWLiomJ0dChQ6/6mQSC2+1WQUGBsrOzbf/guabQTom22oJleTpOVDmiKli2TNnTpsl54YJnnhkzpPnzJT++d+k9u1YffgXV4MGDdeDAgWrjDh48qNTU1DqXcblcNU6FSZ47c1/5YVZUVMjhcCgiIuKqtwvynubyziup3rcXuta6r0dsbKxGjhypkSNH6ic/+YmmT5+uvLw8TZs2rdZtf//731dBQYGefvppde3aVTExMbr33nvldrurzRcXF1drW4PZFq+IiAg5HI5aP69gacxthVJTaadEW8Pa++9Lzz5bY7TzwoWvguqZZ6QxY/y6RuXPe+TX/3KPP/64tm3bpieffFKHDh1Sfn6+li5dqpycHH9W02T07t1bJSUlkjwfypWP6diyZYumTJmie+65R/369VO7du105MiRa67Xe1rU7o84AWCAQYOkUaOkuv4ojojwTB84MGgl+BVUt956q1atWqXf//736tu3r372s59pwYIFmjBhQrDqCwtnzpzR7bffrpUrV+of//iHCgsL9cc//lG/+tWvNHbsWEmenn/r16/XiRMn9OWXX0qSunXrptdff1179+7Vhx9+qPHjx9erU0SbNm0UExOjtWvX6uTJkyoqql9HEgDwm8vl6Xo+YoRneMYMz+sjj3heR4wIatd0qQF3pviv//ov7du3TxcvXtT+/fuN6JoeavHx8crMzNSzzz6roUOHqm/fvvrxj3+shx56SIsWLZIk/frXv1ZBQYFSUlJ83cqfeeYZtWzZUoMGDdKYMWM0cuRI9e/f/5rbi4qK0vPPP68lS5YoOTnZF4YAEBTesHr/fc+1KEl66inPcJBDSjLsMR/XIyE6IaDz+cPlcmn+/Pma7/0AazFmzBiNGTOm2riOHTvqvffeqzbuytOon3zySa0XHadPn67p06dfR9UA4AeXy3MNytut3OEI2vemrmSboOp2YzcdzD0YsjtTAACCwzZBJYkQAgAb4jEfAACjEVQAAKMRVAAAoxFUAACjEVQAAKMRVAAAoxFUAACjEVRhqGPHjlqwYEGoywCARkFQBdCJEyf06KOPqmvXrmrWrJnatm2rwYMHa/HixSotLQ11eQAQlmx1ZwpJUlmZtHWr5x5UDofnoV8bNnhuVR/EGyd+8sknGjx4sFq0aKEnn3xS/fr1k8vl0r59+7R06VK1b99ed999d9C2DwB2Za8jqrIyadw46fbbpccflyorpcce8wyPG+eZHiTf+973FBUVpV27dum+++5Tr1691LlzZ40dO1Z//etffTekPXr0qMaOHav4+HglJibqvvvu08mTJ33rOXz4sMaOHau2bdv67sq+YcOGoNUNAKazT1B5Q2rdOs/wc89J/ftLzz/vGV63LmhhdebMGa1bt045OTmKi4urdR6Hw6HKykqNHTtW//d//6eNGzeqoKBAn3zyie6//37ffOfPn9edd96p9evX6+9//7tGjhypBx54QEePHg143QAQDuxz6m/rVmnt2urjPvzwq98rKz3TP/gg4LemP3TokCzLUo8ePaqNb9WqlS5evCjJ8/iOrKws7du3T4WFhUpJSZEk/c///I/69OmjnTt36tZbb1V6errS09N96/jpT3+qP//5z/rLX/6imTNnBrRuAAgH9jmiGj5cmjXr6vM8+qg0bFijlCNJO3bs0N69e9WnTx+VlZVp//79SklJ8YWU5HlcfYsWLbR//35JniOqOXPmqFevXmrRooUSExN18OBBjqgANFn2OaJyOKRnn5U2bqx+JOWVni4984xnvgDr2rWrHA6HDhw4UG18586dJUkxMTH1XtecOXNUUFCgp59+Wl27dpXL5dK3vvUtlZeXB7RmAAgX9jmisixPB4raQkryjJ892zNfgN14443Kzs7WokWLVFJSUud8vXr10rFjx3Ts2DHfuH/96186e/asevfuLUnasmWLpkyZonvuuUf9+vVTu3btOJoC0KTZJ6g2bPiq40RdnnvOc8QVBC+++KIuXbqkjIwMvfbaa9q/f78OHDiglStX6t///rciIyOVlZWlfv36acKECdqzZ4927NihSZMmadiwYcrIyJAkdevWTa+//rr27t2rDz/8UBMmTJAVhHAFgHBhn6AaNEgaNUqKqNKkKp0SFBHhmT5wYFA236VLF/39739XVlaW5s6dq/T0dGVkZGjhwoWaM2eOfvazn8nhcOiNN95Qy5YtNXToUGVlZalz58567bXXfOt55pln1LJlSw0aNEhjxozRyJEjlZaWFpSaASAc2OcalcslrV7t6YK+dq2n48Qzz3hOBz7/vDRihGd6EL/0m5SUpIULF2rhwoV1ztOhQwe98cYbdU7v2LGj3nvvPd9wZWWlJk6cqMTERN+4I0eOBKReAAgH9gkq6auw+uADT+8+h0NasEC65x7PkVQQQwoAEBz2CirJE0ZVvyflcAT8e1MAgMZjn2tUAABbIqgAAEYjqAAARiOoAABGI6gAAEYjqAAARiOoAABGs3dQVbpDXUGjcTgcWr16dajLAICAs29QHV4m/SHe8xpkU6ZMkcPhkMPhUHR0tLp27aqf/vSnunTpUtC3XZsjR47I4XBo7969Idk+AASS/e5MIXnCaft0SdblV0ldpgV1k6NGjdLy5ctVVlamt99+Wzk5OXI6nZo7d25QtwsAdme/I6qqISXJF1ZBPrJyuVxq166dUlNTNWPGDGVlZenNN99UWVmZ5syZo/bt2ysuLk6ZmZnasGGDb7lXXnlFLVq00DvvvKNevXopPj5eo0aN0vHjx33z7NmzRyNGjFCrVq3UvHlzDRs2THv27Kmzlk6dOkmSbrnlFjkcDg0fPlybNm2S0+nUiRMnqs372GOP6bbbbgvsmwEAAWSvoKoRUl6NE1ZVxcTEqLy8XLm5ufrggw/06quv6h//+Ie+/e1va9SoUfr4449985aWlurpp5/WihUrtGnTJh09elRz5szxTT9//rwmTZqkzZs3a9u2berWrZvuvPNOnTt3rtZt79ixQ5L07rvv6vjx43r99dc1dOhQde7cWStWrPDN53a79b//+7+aNi24R5sAcD3sE1R1hpRX44SVZVl699139c477ygtLU3Lly/XH//4R912223q0qWL5syZoyFDhmj58uW+Zdxut1566SVlZGSof//+ys3N1fr1633Thw4dqokTJ6pnz57q1auXli5dqtLSUm2s4yGQrVu3luR58nC7du10ww03SJIefPDBatv9y1/+oosXL+q+++4LxlsBAAFhj6C6Zkh5BS+s3nrrLcXHx6tZs2YaPXq07r//ft17772qqKhQ9+7dFR8f7/vZuHGjDh8+7Fs2NjZWXbp08Q0nJSXp1KlTvuFTp07p4YcfVrdu3dS8eXMlJibq/Pnzfj+ifsqUKTp06JC2bdsmyXPa8b777lNcXNx1th4Agif8O1NUuqWdM3TtkPKyPPN3+q4U4QxYGd/4xje0ePFiRUdHKzk5WVFRUXrttdcUGRmp3bt3KzIystr88fHxvt+dzup1OByOao+f/973vqeioiI999xzSk1Nlcvl0sCBA1VeXu5XjW3atNGYMWO0fPlyderUSWvWrKl2vQwATBT+QRXhlG5dXM8jKklyeOYPYEhJUlxcnLp27Vpt3C233KKKigqdOnXqujosbN++XYsWLdKdd94pSTp27JhOnz5d5/zR0dGSpIqKihrTpk+frgceeEA33XSTunTposGDBze4LgBoDPY49ddlmpT5siTHNWZ0eOYLcld1r+7du2vChAmaNGmSXn/9dRUWFmrHjh2aP3++/vrXv9Z7PZ07d9bKlSu1f/9+bd++XRMmTFBMTEyd87dp00YxMTFau3atTp48qaKiIt+0kSNHKjExUT//+c81derU62ofADQGewSVVI+watyQ8lq+fLkmTZqk//7v/1aPHj00btw47dy5Ux06dKj3OhYuXKizZ8+qf//++u53v6tZs2apTZs2dc4fFRWl559/XkuWLFFycrLGjh3rmxYREaEpU6aooqJCkyZNuq62AUBjCP9Tf1V5Q6jGacDghtQrr7xS5zSn06m8vDzl5eXVOn3KlCmaMmVKtXHjxo2rdo0qLS1N27dvV0TEV39X3HvvvdWWqTq/5DnFN3369Fq3+dlnn+nOO+9UUlJSnXUDgCnsFVRSLWEVmiMpExUVFWnfvn3Kz8/Xm2++GepyAKBe7BdU0lehtHOGp+MEISVJGjt2rHbs2KFHHnlE2dnZoS4HAOrFnkElecIpwF3Qwx1d0QGEI/t0pqgNIQWgsRSurP6KgDEyqK7sGIDQ4bMA6uHwMmlXruf3XbmNel/RpsCvoJo3b57vuUven549ewasGO/dG/y94wKCp7S0VFLNu2cAuCxET2xoSvy+RtWnTx+9++67X60gKnCXuaKiohQbG6svvvhCTqezWnfsqiorK1VeXq6LFy/WOY9dhKqtlmWptLRUp06dUosWLWrcAgqArv3EBonOXAHgd8pERUWpXbt2wahFDodDSUlJKiws1KefflrnfJZl6cKFC4qJiZHDca27UYS3ULe1RYsWQfu8gbBW3yc2SITVdfI7qD7++GMlJyerWbNmGjhwoObPn3/VuyyUlZWprKzMN1xcXCzJ82gLt9tdY36Hw6GOHTvK7XbXeX3k0qVL2rp1qwYNGhTQIzoThaqtDodDUVFRioyM1KVLlxplm979obb9wk6aSjslG7e1cKW0a6akZr5RbsVUe/XZPlOqcEidJjZigcETqM/Un+Udlh9Xy9esWaPz58+rR48eOn78uPLy8vTZZ5/po48+UkJCQq3LzJs3r9a7MuTn5ys2NrbehQIA7KO0tFTjx49XUVGREhMTrzqvX0F1pbNnzyo1NVXPPPOMHnzwwVrnqe2IKiUlRadPn75mcXVxu90qKChQdna27S/y01b7aSrtlGzc1sKVl3v5ffXfp1sxKohbpuySaXLqQpWZHVLGIlsdUQXiMy0uLlarVq3qFVTXdS6pRYsW6t69uw4dOlTnPC6XSy6Xq8Z4p9N53TtuINYRLmir/TSVdko2bGv3qVKkVes1KqcuVAkq7y3c7Pekguv9TP1Z9rq6kZ0/f16HDx/m5qYAmh5Dn9hgR34F1Zw5c7Rx40YdOXJEW7du1T333KPIyEg98MADwaoPAMxVZ1gRUoHk16m///znP3rggQd05swZtW7dWkOGDNG2bdvUunXrYNUHAGbzPbFh5uURhFSg+RVUr776arDqAIDw1WWapwv6fnk6TtjwmlQo2fu2DgDQWLy9+mzSu88kBBUAwGgEFQDAaAQVAMBoBBUAwGgEFQDAaAQVAMBoBBUAwGgEFQDAaAQVAMBoBBUAwGgEFQDAaAQVAMBoBBUAwGgEFQDAaAQVAMBoBBUAwGgEFQDAaAQVAMBoBBUAwGgEFQDAaAQVAMBoBBUAwGgEFQDAaAQVAMBoBBUAwGgEFQDAaAQVAMBoBBUAwGgEFQDAaAQVAMBoBBUAwGgEFQDAaAQVAMBoBBUAwGgEFQDAaAQVAMBoBBUAwGgEFQDAaAQVAMBoBBUAwGgEFQDAaAQVAMBoBBUAwGgEFQDAaOEZVIUrq78CAGwr/ILq8DJpV67n9125nmEAgG1dV1A99dRTcjgceuyxxwJUzjUcXiZtny7JujzC8gwTVgBgWw0Oqp07d2rJkiVKS0sLZD11qxFSXoQVANhZg4Lq/PnzmjBhgn7zm9+oZcuWga6ppjpDyouwAgC7imrIQjk5ObrrrruUlZWln//851edt6ysTGVlZb7h4uJiSZLb7Zbb7b72xgpXSrtmSmrmG+VWTLVXn+0zpQqH1Gli/RoSBrzvUb3eqzDXVNraVNop0VY7ClQ7/VneYVlWXYcptXr11Vf1i1/8Qjt37lSzZs00fPhw3XzzzVqwYEGt88+bN095eXk1xufn5ys2NtafTQMAbKK0tFTjx49XUVGREhMTrzqvX0F17NgxZWRkqKCgwHdt6lpBVdsRVUpKik6fPn3N4iRdPqLKVdXTfm7FqCBumbJLpsmpC1WbI2Usst0RVUFBgbKzs+V0OkNdTlA1lbY2lXZKtNWOAtXO4uJitWrVql5B5depv927d+vUqVPq37+/b1xFRYU2bdqkRYsWqaysTJGRkdWWcblccrlcNdbldDrr18juU6VIq9ZrVE5dqBJUDinzZanLVH+aFDbq/X7ZQFNpa1Npp0Rb7eh62+nPsn4F1R133KF9+/ZVGzd16lT17NlTP/jBD2qEVMB0meZ5rbNDhTekpgVn+wCAkPErqBISEtS3b99q4+Li4nTjjTfWGB9w1cKqKkIKAOwsvO5M0WWaJ5TkuDyCkAIAu2tQ9/SqNmzYEIAy/NBlmqcL+n55Ok7Y9JoUAMAjvI6ovLy9+mzUuw8AULvwDCoAQJNBUAEAjEZQAQCMRlABAIxGUAEAjEZQAQCMRlABAIxGUAEAjEZQAQCMRlABAIxGUAEAjEZQAQCMRlABAIxGUAEAjEZQAQCMRlABAIxGUAEAjEZQAQCMRlABAIxGUAEAjEZQAQCMRlABAIxGUAEAjEZQAQCMRlABAIxGUAEAjEZQAQCMRlABAIxGUAEAjEZQAQCMRlABAIxGUAEAjEZQAQCMRlABAIxGUAEAjEZQAQCMRlABAIxGUAEAjEZQAQCMRlABAIxGUAEAjEZQAQCMRlABAIxGUAEAjEZQAQCMFp5BVbiy+isQTth/Ec5CsP/6FVSLFy9WWlqaEhMTlZiYqIEDB2rNmjXBqq12h5dJu3I9v+/K9QwD4YL9F+EsRPuvX0F100036amnntLu3bu1a9cu3X777Ro7dqz++c9/Bqu+6g4vk7ZPl2RdHmF5hvnHjnDA/otwFsL9N8qfmceMGVNt+Be/+IUWL16sbdu2qU+fPgEtrIYab5LX5TdLkrpMC24NQEOx/yKchXj/9SuoqqqoqNAf//hHlZSUaODAgYGsqaY63yQv/rHDYOy/CGcG7L9+B9W+ffs0cOBAXbx4UfHx8Vq1apV69+5d5/xlZWUqKyvzDRcXF0uS3G633G73tTdYuFLaNVNSM98ot2KqvfpsnylVOKROE+vfIMN536N6vVdhzpZtZf+t9mpntmxrEPdff94nh2VZdcVkrcrLy3X06FEVFRXpT3/6k15++WVt3LixzrCaN2+e8vLyaozPz89XbGysP5sGANhEaWmpxo8fr6KiIiUmJl51Xr+D6kpZWVnq0qWLlixZUuv02o6oUlJSdPr06WsWJ+lyoueq6mGnWzEqiFum7JJpcupClZkdUsYi2/1FWlBQoOzsbDmdzlCXE1S2bCv7r/0+0zrYsq1B3H+Li4vVqlWregVVg69ReVVWVlYLoiu5XC65XK4a451OZ/0+zO5TpUir1nOkTl2o8kY5pMyXpS5T/ag+fNT7/bIBW7WV/VeSzT7Ta7BVW4O4//rzHvkVVHPnztXo0aPVoUMHnTt3Tvn5+dqwYYPeeecdf1bjP+8Fujov6HnfJC5Ew0DsvwhnBuy/fgXVqVOnNGnSJB0/flzNmzdXWlqa3nnnHWVnZwervq9Ue7Oq4h85wgD7L8JZiPdfv4Lqt7/9bbDqqB/fmzXz8gj+kSOMsP8inIVw/73ua1SNrss0TxfI/fJcuLPpOX3YFPsvwlmI9t/wvCmtt1eJjXpHoQlh/0U4C8H+G55BBQBoMggqAIDRCCoAgNEIKgCA0QgqAIDRCCoAgNEIKgCA0QgqAIDRCCoAgNEIKgCA0QgqAIDRCCoAgNEIKgCA0QgqAIDRCCoAgNEIKgCA0QgqAIDRCCoAgNEIKgCA0QgqAIDRCCoAgNEIKgCA0QgqAIDRCCoAgNEIKgCA0QgqAIDRCCoAgNEIKgCA0QgqAIDRCCoAgNEIKgCA0QgqAIDRCCoAgNEIKgCA0QgqAIDRCCoAgNEIKgCA0QgqAIDRCCoAgNEIKgCA0QgqAIDRCCoAgNEIKgCA0QgqAIDRCCoAwVO4svor0AAEFYDgOLxM2pXr+X1XrmcYaAC/gmr+/Pm69dZblZCQoDZt2mjcuHE6cOBAsGoDEK4OL5O2T5dkXR5heYYJKzSAX0G1ceNG5eTkaNu2bSooKJDb7daIESNUUlISrPoAhJsaIeVFWKFhovyZee3atdWGX3nlFbVp00a7d+/W0KFDA1oYgDBUZ0h5XQ4rSeoyrbGqQpjzK6iuVFRUJEm64YYb6pynrKxMZWVlvuHi4mJJktvtltvtbtB2vcs1dPlwQlvtx7btLFwp7ZopqZlvlFsx1V59ts+UKhxSp4mNWGBw2fZzvUKg2unP8g7Lsur60+eqKisrdffdd+vs2bPavHlznfPNmzdPeXl5Ncbn5+crNja2IZsGAIS50tJSjR8/XkVFRUpMTLzqvA0OqhkzZmjNmjXavHmzbrrppjrnq+2IKiUlRadPn75mcXVxu90qKChQdna2nE5ng9YRLmir/di2nYUrL/fy++q/FLdiVBC3TNkl0+TUhSozO6SMRbY7orLl53qFQLWzuLhYrVq1qldQNejUX25urt566y1t2rTpqiElSS6XSy6Xq8Z4p9N53R9mINYRLmir/diund2nSpFWrdeonLpQJagcUubLUpepjV5iY7Dd51qH622nP8v6FVSWZWnmzJlatWqVNmzYoE6dOvldHAAb83aQqLNDhTek6EiB+vMrqHJycpSfn6833nhDCQkJOnHihCSpefPmiomJucbSAJqEamFVFSGFhvHre1SLFy9WUVGRhg8frqSkJN/Pa6+9Fqz6AISjLtM8oSTH5RGEFBrO71N/AFAvXaZ5uqDvl6fjhE2vSSH4uNcfgODx9uqzUe8+ND6CCgBgNIIKAGA0ggoAYDSCCgBgNIIKAGA0ggoAYDSCCgBgNIIKAGA0ggoAYDSCCgBgNIIKAGA0ggoAYDSCCgBgNIIKAGA0ggoAYDSCCgBgNIIKAGA0ggoAYDSCCgBgNIIKAGA0ggoAYDSCCgBgNIIKAGA0ggoAYDSCCgBgNIIKAGA0ggoAYDSCCgBgNIIKAGA0ggoAYDSCCgBgNIIKAGA0ggoAYDSCCgBgNIIKAGA0ggoAYDSCCgBgNIIKAGA0ggoAYDSCCgBgNIIKAGA0ggoAYDSCCgBgNIIKAGA0ggrmKFxZ/RUARFDBFIeXSbtyPb/vyvUMA4AaEFSbNm3SmDFjlJycLIfDodWrVwehLDQph5dJ26dLsi6PsDzDhBUANSCoSkpKlJ6erhdeeCEY9aCpqRFSXoQVAI8ofxcYPXq0Ro8eHYxa0NTUGVJel8NKkrpMa6yqABjG76DyV1lZmcrKynzDxcXFkiS32y23292gdXqXa+jy4cS2bS1cKe2aKamZb5RbMdVefbbPlCocUqeJjVhg8Nj2M60FbbWfQLXTn+UdlmXV9efstRd2OLRq1SqNGzeuznnmzZunvLy8GuPz8/MVGxvb0E0DAMJYaWmpxo8fr6KiIiUmJl513qAHVW1HVCkpKTp9+vQ1i6uL2+1WQUGBsrOz5XQ6G7SOcGHbthauvNzL76vdz60YFcQtU3bJNDl1ocrMDiljka2OqGz5mdaCttpPoNpZXFysVq1a1Suogn7qz+VyyeVy1RjvdDqv+8MMxDrChe3a2n2qFGnVeo3KqQtVgsohZb4sdZna6CUGm+0+06ugrfZzve30Z1m+R4XQ6TLNE0Jy1DGDN6ToSAE0ZX4fUZ0/f16HDh3yDRcWFmrv3r264YYb1KFDh4AWhybAG0Le3n0+hBQAD7+DateuXfrGN77hG549e7YkafLkyXrllVcCVhiaEF9Yzbw8gpAC8BW/g2r48OG6jv4XQO26TPN0Qd8vT8cJG16TAtAwXKOCOby9+mzSuw9AYBBUAACjEVQAAKMRVAAAoxFUAACjEVQAAKMRVAAAoxFUAACjEVQAAKMRVAAAoxFUAACjEVQAAKMRVAAAoxFUAACjEVQAAKMRVAAAoxFUAACjEVQAAKMRVAAAoxFUAACjEVQAAKMRVAAAoxFUAACjEVQAAKMRVAAAoxFUAACjEVQAAKMRVAAAoxFUAACjEVQAAKMRVAAAoxFUAACjEVQAAKMRVAAAoxFUAACjEVQAAKMRVAAAoxFUAACjEVQAAKMRVAAAoxFUAACjEVQAAKMRVAAAoxFUAACjEVQAAKMRVAAAoxFUpitcWf0VAJqYBgXVCy+8oI4dO6pZs2bKzMzUjh07Al1XDR+f+Vh7ju/RnuN79OHJDyVJH5780Dfu4zMfB72GRnd4mbQr1/P7rlzPMAA0MVH+LvDaa69p9uzZeumll5SZmakFCxZo5MiROnDggNq0aROMGvXxmY/VfVF333BMRIx+n/Z7DV0+VBcqL/jGH8w9qG43dgtKDY3u8DJp+3RJzS6PsC4PS+oyLVRVAUCj8/uI6plnntFDDz2kqVOnqnfv3nrppZcUGxurZcuC99f+ufJzAZ3PeL6Qsq6YcDmsOLIC0IT4FVTl5eXavXu3srKyvlpBRISysrL0wQcfBLy4JqnOkPIirAA0LX6d+jt9+rQqKirUtm3bauPbtm2rf//737UuU1ZWprKyMt9wcXGxJMntdsvtdtdru5UVlYqJiPENe3+vOs47X33XaaTCldKumfrqdJ/kVky1V5/tM6UKh9RpYiMWGFzezy6sP8N6aCrtlGirHQWqnf4s77Asq64/3Wv4/PPP1b59e23dulUDBw70jf/+97+vjRs3avv27TWWmTdvnvLy8mqMz8/PV2xsbL0LBQDYR2lpqcaPH6+ioiIlJiZedV6/jqhatWqlyMhInTx5str4kydPql27drUuM3fuXM2ePds3XFxcrJSUFI0YMeKaxXl9ePJDDV0+1DccExGjZX2XadpH06p1ptg0dZPS26b70ySzFK683Mvvq78d3IpRQdwyZZdMk1MXqszskDIW2e6IqqCgQNnZ2XI6naEuJ2iaSjsl2mpHgWqn9+xaffgVVNHR0fra176m9evXa9y4cZKkyspKrV+/Xrm5ubUu43K55HK5aox3Op31bmREZES1QPK6UHmh2viIyIjw3kG6T5UirVqvUTl1oUpQOaTMl6UuUxu9xMbgz74RzppKOyXaakfX205/lvW7e/rs2bM1efJkZWRkaMCAAVqwYIFKSko0dao9/9NsdN6u53V2qPCGFF3UATQNfgfV/fffry+++EI/+clPdOLECd18881au3ZtjQ4WgZQQnRDQ+YxXLayqIqQAND1+B5Uk5ebm1nmqLxi63dhNB3MP+r4nVVlRqc92f6ZNUzcpItLTwz4hOsE+X/aVqoTVzMsjCCkATVODgioUqoaQ2+3WZ/pM6W3T7X0uuMs0Txf0/fJ0nLDpNSkAuBpuSms6b68+G/XuAwB/EFQAAKMRVAAAoxFUAACjEVQAAKMRVAAAoxFUAACjEVQAAKMRVAAAozX6nSm8j7/y5xbvV3K73SotLVVxcbG970wh2mpHTaWdEm21o0C105sB9XkkYqMH1blznvv1paSkNPamAQCGOXfunJo3b37Vefx6wm8gVFZW6vPPP1dCQoIcDkeD1uF9+OKxY8fq/fDFcEVb7aeptFOirXYUqHZalqVz584pOTlZERFXvwrV6EdUERERuummmwKyrsTERFvvEFXRVvtpKu2UaKsdBaKd1zqS8qIzBQDAaAQVAMBoYRlULpdLTzzxhFwuV6hLCTraaj9NpZ0SbbWjULSz0TtTAADgj7A8ogIANB0EFQDAaAQVAMBoBBUAwGhhGVQvvPCCOnbsqGbNmikzM1M7duwIdUkBt2nTJo0ZM0bJyclyOBxavXp1qEsKivnz5+vWW29VQkKC2rRpo3HjxunAgQOhLisoFi9erLS0NN8XJQcOHKg1a9aEuqyge+qpp+RwOPTYY4+FupSAmzdvnhwOR7Wfnj17hrqsoPnss880ceJE3XjjjYqJiVG/fv20a9euoG837ILqtdde0+zZs/XEE09oz549Sk9P18iRI3Xq1KlQlxZQJSUlSk9P1wsvvBDqUoJq48aNysnJ0bZt21RQUCC3260RI0aopKQk1KUF3E033aSnnnpKu3fv1q5du3T77bdr7Nix+uc//xnq0oJm586dWrJkidLS0kJdStD06dNHx48f9/1s3rw51CUFxZdffqnBgwfL6XRqzZo1+te//qVf//rXatmyZfA3boWZAQMGWDk5Ob7hiooKKzk52Zo/f34IqwouSdaqVatCXUajOHXqlCXJ2rhxY6hLaRQtW7a0Xn755VCXERTnzp2zunXrZhUUFFjDhg2zHn300VCXFHBPPPGElZ6eHuoyGsUPfvADa8iQISHZdlgdUZWXl2v37t3KysryjYuIiFBWVpY++OCDEFaGQCkqKpIk3XDDDSGuJLgqKir06quvqqSkRAMHDgx1OUGRk5Oju+66q9q/Vzv6+OOPlZycrM6dO2vChAk6evRoqEsKijfffFMZGRn69re/rTZt2uiWW27Rb37zm0bZdlgF1enTp1VRUaG2bdtWG9+2bVudOHEiRFUhUCorK/XYY49p8ODB6tu3b6jLCYp9+/YpPj5eLpdLjzzyiFatWqXevXuHuqyAe/XVV7Vnzx7Nnz8/1KUEVWZmpl555RWtXbtWixcvVmFhoW677Tbf44zs5JNPPtHixYvVrVs3vfPOO5oxY4ZmzZql3/3ud0HfdqPfPR2oS05Ojj766CPbnuOXpB49emjv3r0qKirSn/70J02ePFkbN260VVgdO3ZMjz76qAoKCtSsWbNQlxNUo0eP9v2elpamzMxMpaam6g9/+IMefPDBEFYWeJWVlcrIyNCTTz4pSbrlllv00Ucf6aWXXtLkyZODuu2wOqJq1aqVIiMjdfLkyWrjT548qXbt2oWoKgRCbm6u3nrrLb3//vsBewyMiaKjo9W1a1d97Wtf0/z585Wenq7nnnsu1GUF1O7du3Xq1Cn1799fUVFRioqK0saNG/X8888rKipKFRUVoS4xaFq0aKHu3bvr0KFDoS4l4JKSkmr8QdWrV69GOdUZVkEVHR2tr33ta1q/fr1vXGVlpdavX2/b8/x2Z1mWcnNztWrVKr333nvq1KlTqEtqVJWVlSorKwt1GQF1xx13aN++fdq7d6/vJyMjQxMmTNDevXsVGRkZ6hKD5vz58zp8+LCSkpJCXUrADR48uMZXRw4ePKjU1NSgbzvsTv3Nnj1bkydPVkZGhgYMGKAFCxaopKREU6dODXVpAXX+/Plqf5UVFhZq7969uuGGG9ShQ4cQVhZYOTk5ys/P1xtvvKGEhATftcbmzZsrJiYmxNUF1ty5czV69Gh16NBB586dU35+vjZs2KB33nkn1KUFVEJCQo1rjHFxcbrxxhttd+1xzpw5GjNmjFJTU/X555/riSeeUGRkpB544IFQlxZwjz/+uAYNGqQnn3xS9913n3bs2KGlS5dq6dKlwd94SPoaXqeFCxdaHTp0sKKjo60BAwZY27ZtC3VJAff+++9bkmr8TJ48OdSlBVRtbZRkLV++PNSlBdy0adOs1NRUKzo62mrdurV1xx13WOvWrQt1WY3Crt3T77//fispKcmKjo622rdvb91///3WoUOHQl1W0PzlL3+x+vbta7lcLqtnz57W0qVLG2W7POYDAGC0sLpGBQBoeggqAIDRCCoAgNEIKgCA0QgqAIDRCCoAgNEIKgCA0QgqAIDRCCoAgNEIKgCA0QgqAIDRCCoAgNH+P0/20vZLSUUzAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(5, 5))\n",
        "plt.scatter(0, 0, c='green', marker='s', label='Start')\n",
        "plt.scatter(GOAL[0], GOAL[1], c='red', marker='X', label='Goal')\n",
        "for i, (px, py) in enumerate(PENALTIES):\n",
        "    if i == 0:\n",
        "        plt.scatter(px, py, c='orange', marker='D', label='Penalty')\n",
        "    else:\n",
        "        plt.scatter(px, py, c='orange', marker='D')\n",
        "plt.xticks(range(GRID_SIZE))\n",
        "plt.yticks(range(GRID_SIZE))\n",
        "plt.title(\"Grid World\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLm0Q_NUVkW5"
      },
      "source": [
        "# REINFORCE Algorithm (30 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC1g8VL_VkW5"
      },
      "source": [
        "The REINFORCE algorithm updates policy parameters by using the log-probability of actions multiplied by the discounted return.\n",
        "\n",
        "This algorithm optimizes a **stochastic policy** $( \\pi_{\\theta}(a_t \\mid s_t) )$ by updating its parameters in the direction that increases expected rewards. The update rule is based on the **policy gradient theorem**:  \n",
        "\n",
        "$$[\n",
        "\\theta \\leftarrow \\theta + \\alpha \\sum_{t=0}^{T} \\nabla_{\\theta} \\log \\pi_{\\theta}(a_t \\mid s_t) G_t\n",
        "]$$\n",
        "\n",
        "where:  \n",
        "\n",
        "- $( \\theta )$ are the policy parameters (weights of the neural network).  \n",
        "- $( \\alpha )$ is the learning rate.  \n",
        "- $( G_t )$ is the **discounted return** from timestep $( t )$:  \n",
        "\n",
        "$$[\n",
        "G_t = \\sum_{k=0}^{T-t} \\gamma^k R_{t+k}\n",
        "]$$\n",
        "\n",
        "- $( \\nabla_{\\theta} \\log \\pi_{\\theta}(a_t \\mid s_t) )$ is the gradient of the log-probability of the selected action, used to adjust the policy in the correct direction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpvODJhGVkW5"
      },
      "source": [
        "### Policy Network Definition (10 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NDniXDH8VkW5"
      },
      "outputs": [],
      "source": [
        "class PolicyNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = self.fc2(torch.relu(self.fc1(state)))\n",
        "        return torch.log_softmax(x, dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3s9oBcxVkW5"
      },
      "source": [
        "### REINFORCE Agent Implementation (20 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SFgBI88IVkW6"
      },
      "outputs": [],
      "source": [
        "class ReinforceAgent:\n",
        "    def __init__(self, lr=0.005, gamma=0.99):\n",
        "        self.input_dim = 2\n",
        "        self.output_dim = len(ACTIONS)\n",
        "        self.hidden_dim = 512\n",
        "        self.policy_net = PolicyNetwork(self.input_dim, self.output_dim, self.hidden_dim)\n",
        "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=lr)\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def train(self, episodes=6000, epsilon=1.0, epsilon_decay=0.9995, min_epsilon=0.01):\n",
        "        for episode in range(episodes):\n",
        "            state = (0, 0)\n",
        "            trajectory, rewards = [], []\n",
        "            STOP = 0\n",
        "\n",
        "            while state != GOAL and STOP <= 100:\n",
        "                state_tensor = torch.tensor(state, dtype=torch.float32)\n",
        "                log_action_probs = self.policy_net(state_tensor).detach().numpy()\n",
        "                action_probs = np.exp(log_action_probs)\n",
        "\n",
        "                random_value = random.random()\n",
        "\n",
        "                # Using an epsilon-greedy strategy to balance exploration & exploitation:\n",
        "                if random_value < epsilon:\n",
        "                    action = random.randint(0, self.output_dim)\n",
        "                else:\n",
        "                    best_action_index = np.argmax(action_probs)\n",
        "                    action = ACTIONS[best_action_index]\n",
        "\n",
        "                new_state, reward = grid_world.step(state, action)\n",
        "\n",
        "                trajectory.append((state, action, reward))\n",
        "\n",
        "                rewards.append(reward)\n",
        "\n",
        "                state = new_state\n",
        "\n",
        "            returns, G = [], 0\n",
        "            for r in reversed(rewards):\n",
        "                G = r + self.gamma * G\n",
        "                returns.insert(0, G)\n",
        "\n",
        "            returns = torch.tensor(returns, dtype=torch.float32)\n",
        "            baseline = returns.mean()\n",
        "            returns -= baseline\n",
        "\n",
        "            loss = 0\n",
        "            for (state, action, _), G in zip(trajectory, returns):\n",
        "                state_tensor = torch.tensor(state, dtype=torch.float32)\n",
        "                log_action_probs = self.policy_net(state_tensor)\n",
        "                loss -= log_action_probs[ACTION_IDX[action]] * G\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            epsilon = max(min_epsilon, epsilon * epsilon_decay)\n",
        "\n",
        "            if episode % 5 == 0:\n",
        "                print(f\"Episode {episode}: Total Reward = {sum(rewards)}, Epsilon = {epsilon:.4f}\")\n",
        "\n",
        "    def get_optimal_trajectory(self):\n",
        "        state = (0, 0)\n",
        "        trajectory = [state]\n",
        "        rewards = 0\n",
        "        while state != GOAL:\n",
        "            state_tensor = torch.tensor(state, dtype=torch.float32)\n",
        "            log_action_probs = self.policy_net(state_tensor).detach().numpy()\n",
        "            action_probs = np.exp(log_action_probs)\n",
        "            action = np.random.choice(ACTIONS, p=action_probs / action_probs.sum())\n",
        "            state, reward = grid_world.step(state, action)\n",
        "            rewards += reward\n",
        "            trajectory.append(state)\n",
        "        return trajectory, rewards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kq55_sVbVkW6"
      },
      "source": [
        "# Genetic Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_TK-j01VkW6"
      },
      "source": [
        "\n",
        "Genetic Algorithms (GAs) are optimization algorithms inspired by **natural selection**. They evolve a population of candidate solutions over multiple generations to find an optimal or near-optimal solution.\n",
        "\n",
        "#### **1. Population ($P$)**\n",
        "A **population** consists of multiple candidate solutions (individuals). Each individual represents a **policy or solution** encoded as a chromosome.\n",
        "\n",
        "$$[\n",
        "P_t = \\{ X_1^t, X_2^t, ..., X_N^t \\}\n",
        "]$$\n",
        "\n",
        "where:\n",
        "- $( P_t )$ is the population at generation $( t )$,\n",
        "- $( X_i^t )$ is the $( i )$-th individual in the population,\n",
        "- $( N )$ is the population size.\n",
        "\n",
        "#### **2. Fitness Function ($F$)**\n",
        "Each individual is evaluated using a **fitness function**, which measures how good a solution is.\n",
        "\n",
        "$$[\n",
        "F(X_i) = \\text{reward or performance score of } X_i\n",
        "]$$\n",
        "\n",
        "#### **3. Selection**\n",
        "The best individuals are selected based on their fitness scores to produce the next generation. Common methods include:\n",
        "- **Roulette Wheel Selection** (Probability proportional to fitness)\n",
        "- **Tournament Selection** (Select the best out of a subset)\n",
        "\n",
        "#### **4. Crossover (Recombination)**\n",
        "Two parents **combine genetic information** to create offspring. A common method is **single-point crossover**, where a random crossover point is chosen.\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\text{Parent 1} &= (A_1, A_2, | A_3, A_4, A_5) \\\\\n",
        "\\text{Parent 2} &= (B_1, B_2, | B_3, B_4, B_5) \\\\\n",
        "\\text{Offspring 1} &= (A_1, A_2, | B_3, B_4, B_5) \\\\\n",
        "\\text{Offspring 2} &= (B_1, B_2, | A_3, A_4, A_5)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "#### **5. Mutation**\n",
        "Mutation introduces small **random changes** in individuals to maintain diversity and avoid local optima. If $( X_i )$ is an individual, a mutation function $( M )$ alters some genes:\n",
        "\n",
        "$$[\n",
        "X_i' = M(X_i)\n",
        "]$$\n",
        "\n",
        "For example, if an individual’s policy is `['up', 'right', 'down']`, mutation might randomly change `right` to `left`.\n",
        "\n",
        "#### **6. Generations & Evolution**\n",
        "The new population is formed after selection, crossover, and mutation. The process repeats for **multiple generations** until a stopping criterion is met (e.g., max generations or convergence).\n",
        "\n",
        "$$[\n",
        "P_{t+1} = \\text{next\\_generation}(P_t)\n",
        "]$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhuDXH6gVkW6"
      },
      "source": [
        "### Genetic Algorithm Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dTb0hWMKVkW6"
      },
      "outputs": [],
      "source": [
        "class GeneticAlgorithm:\n",
        "    def __init__(self, population_size, mutation_rate, crossover_rate, policy_network, generations=100, device='cpu'):\n",
        "        self.device = device\n",
        "        self.population_size = population_size\n",
        "        self.mutation_rate = mutation_rate\n",
        "        self.crossover_rate = crossover_rate\n",
        "        self.generations = generations\n",
        "        self.policy_network = policy_network.to(self.device)  # Move the model to GPU\n",
        "        self.population = [self._initialize_individual() for _ in range(population_size)]\n",
        "\n",
        "    def _initialize_individual(self):\n",
        "        # Initialize an individual by setting random weights for the policy network\n",
        "        individual = {}\n",
        "        for name, param in self.policy_network.named_parameters():\n",
        "            individual[name] = torch.randn_like(param).to(self.device)  # Move individual weights to GPU\n",
        "        return individual\n",
        "\n",
        "    def _evaluate_individual(self, individual):\n",
        "        # Simulate the evaluation (for example, run a few episodes in GridWorld environment)\n",
        "        self._apply_individual_weights(individual)\n",
        "        state = (0, 0)\n",
        "        STOP = 0\n",
        "        trajectory, rewards = [], []\n",
        "        while state != GOAL and STOP <= 150:\n",
        "            state_tensor = torch.tensor(state, dtype=torch.float32).to(self.device)  # Move state to GPU\n",
        "            log_action_probs = self.policy_network(state_tensor)\n",
        "            action_probs = torch.exp(log_action_probs)\n",
        "            action_idx = torch.argmax(action_probs).item()  # Get action with highest probability\n",
        "            action = ACTIONS[action_idx]  # Map action index back to action\n",
        "            new_state, reward = grid_world.step(state, action)\n",
        "            trajectory.append((state, action, reward))\n",
        "            rewards.append(reward)\n",
        "            state = new_state\n",
        "            STOP += 1\n",
        "        return sum(rewards)\n",
        "\n",
        "    def _apply_individual_weights(self, individual):\n",
        "        # Apply the weights of an individual to the policy network\n",
        "        for name, param in individual.items():\n",
        "            self.policy_network.state_dict()[name].copy_(param)\n",
        "\n",
        "    def _select_parents(self):\n",
        "        # Select two individuals based on fitness (higher reward is better)\n",
        "        scores = [(ind, self._evaluate_individual(ind)) for ind in self.population]\n",
        "        sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
        "        parent1 = sorted_scores[0][0]\n",
        "        parent2 = sorted_scores[1][0]\n",
        "        return parent1, parent2\n",
        "\n",
        "    def _crossover(self, parent1, parent2):\n",
        "        # Perform crossover to combine the genetic material of two parents\n",
        "        child = {}\n",
        "        for name in parent1.keys():\n",
        "            if random.random() < self.crossover_rate:\n",
        "                child[name] = parent1[name]\n",
        "            else:\n",
        "                child[name] = parent2[name]\n",
        "        return child\n",
        "\n",
        "    def _mutate(self, individual):\n",
        "        # Perform mutation (randomly modify the weights)\n",
        "        for name, param in individual.items():\n",
        "            if random.random() < self.mutation_rate:\n",
        "                individual[name] = torch.randn_like(param).to(self.device)  # Ensure mutated weight is on GPU\n",
        "        return individual\n",
        "\n",
        "    def run(self):\n",
        "        for generation in range(self.generations):\n",
        "            new_population = []\n",
        "            for _ in range(self.population_size // 2):\n",
        "                parent1, parent2 = self._select_parents()\n",
        "                child1 = self._crossover(parent1, parent2)\n",
        "                child2 = self._crossover(parent2, parent1)\n",
        "                new_population.append(self._mutate(child1))\n",
        "                new_population.append(self._mutate(child2))\n",
        "            self.population = new_population\n",
        "            print(f\"Generation {generation + 1} completed\")\n",
        "\n",
        "    def get_optimal_trajectory(self):\n",
        "        state = (0, 0)\n",
        "        trajectory = [state]\n",
        "        rewards = 0\n",
        "        STOP = 0\n",
        "        while state != GOAL and STOP <= 150:\n",
        "            state_tensor = torch.tensor(state, dtype=torch.float32).to(self.device)  # Move state to GPU\n",
        "            log_action_probs = self.policy_network(state_tensor)\n",
        "            action_probs = torch.exp(log_action_probs)\n",
        "            action_idx = torch.argmax(action_probs).item()  # Get action with highest probability\n",
        "            action = ACTIONS[action_idx]  # Map action index back to action\n",
        "            state, reward = grid_world.step(state, action)\n",
        "            rewards += reward\n",
        "            trajectory.append(state)\n",
        "            STOP += 1\n",
        "        return trajectory, rewards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2_rrmBCVkW6"
      },
      "source": [
        "# Running & Comparing Agents (20 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISBNYDieVkW6"
      },
      "outputs": [],
      "source": [
        "# Train REINFORCE agent\n",
        "\n",
        "LEARNING_RATE = 0.001\n",
        "GAMMA = 0.99\n",
        "\n",
        "reinforce_agent = ReinforceAgent(lr=LEARNING_RATE, gamma=GAMMA)\n",
        "reinforce_agent.train(episodes=6000, epsilon=1.0, epsilon_decay=0.9995, min_epsilon=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u-6R1O0VkW7"
      },
      "outputs": [],
      "source": [
        "# Train Genetic Algorithm agent\n",
        "\n",
        "POPULATION_SIZE = 12\n",
        "GENERATIONS = 1000\n",
        "MUTATION_RATE = 0.2\n",
        "CROSSOVER_RATE = 0.8\n",
        "\n",
        "policy_network = PolicyNetwork()\n",
        "genetic_agent = GeneticAlgorithm(generations=GENERATIONS, population_size=POPULATION_SIZE, mutation_rate=MUTATION_RATE, crossover_rate=CROSSOVER_RATE, policy_network=policy_network, device=device)\n",
        "optimal_genetic_policy = genetic_agent.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLk5xtH9VkW7"
      },
      "source": [
        "# Visualizing Results (40 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es2e9ubnVkW7"
      },
      "source": [
        "Plots the agent’s trajectory in the Grid World."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEbA7yzOVkW7"
      },
      "outputs": [],
      "source": [
        "def visualize_trajectory(trajectory, title):\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    x_vals, y_vals = zip(*trajectory)\n",
        "    plt.plot(x_vals, y_vals, marker='o', color='blue', linestyle='-', alpha=0.7)\n",
        "    plt.scatter(0, 0, c='green', marker='s', label='Start')\n",
        "    plt.scatter(GOAL[0], GOAL[1], c='red', marker='X', label='Goal')\n",
        "    for i, (px, py) in enumerate(PENALTIES):\n",
        "        if i == 0:\n",
        "            plt.scatter(px, py, c='orange', marker='D', label='Penalty')\n",
        "        else:\n",
        "            plt.scatter(px, py, c='orange', marker='D')\n",
        "    plt.xticks(range(GRID_SIZE))\n",
        "    plt.yticks(range(GRID_SIZE))\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g45-MsSlVkW7"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7q8Cm2AVkW7"
      },
      "outputs": [],
      "source": [
        "# Results\n",
        "\n",
        "optimal_reinforce_trajectory, final_reward_reinforce = reinforce_agent.get_optimal_trajectory()\n",
        "print(f\"Final Reward (REINFORCE): {final_reward_reinforce}\\n\")\n",
        "visualize_trajectory(optimal_reinforce_trajectory, \"REINFORCE Optimal Policy\")\n",
        "\n",
        "print(\"\\n--------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "optimal_genetic_trajectory, final_reward_genetic = genetic_agent.get_optimal_trajectory()\n",
        "print(f\"Final Reward (Genetic Algorithm): {final_reward_genetic}\\n\")\n",
        "visualize_trajectory(optimal_genetic_trajectory, \"Genetic Algorithm Optimal Policy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT86bSuuVkW7"
      },
      "source": [
        "$\\bullet$ Based on the implementation and results from comparing policy search using Genetic Algorithm (GA) and the REINFORCE algorithm:\n",
        "\n",
        "**Question 1:** (10 points)\n",
        "\n",
        "How do these two methods differ in terms of their effectiveness for solving reinforcement learning tasks?\n",
        "\n",
        "**Question 2:** (15 points)\n",
        "\n",
        "Discuss the key differences in their **performance**, **convergence rates**, and **stability**.\n",
        "\n",
        "**Question 3:** (15 points)\n",
        "\n",
        "Additionally, explore how each method handles exploration and exploitation, and suggest situations where one might be preferred over the other.\n",
        "\n",
        "<br/>\n",
        "............\n",
        "<br/>\n",
        "............\n",
        "<br/>\n",
        "............"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}