{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0lz4fO49hX-"
      },
      "source": [
        "# Run this Notebook\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DeepRLCourse/Homework-1-Questions/blob/main/HW1_Notebook.ipynb)  \n",
        "[![Open in Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/DeepRLCourse/Homework-1-Questions/blob/main/HW1_Notebook.ipynb)\n",
        "\n",
        "# HW1: Introduction to RL\n",
        "> - Full Name: **Parsa Ghezelbash**\n",
        "> - Student ID: **401110437**\n",
        "\n",
        "\n",
        "This notebook is designed to provide hands-on experience with RL modeling, algorithm implementation, and performance evaluation. Students will explore RL concepts through predefined environments and custom-designed settings.\n",
        "\n",
        "Follow the instructions in each section to complete the homework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MVMgXuu9hX_"
      },
      "source": [
        "## Setup Instructions\n",
        "Seting up RL dependecies for first time may be challenging. Some  torch or gymnasium (Sklearn lib in SL world!) environments need additional set up on your system. If you encountered error and failure after hours of search and try, feel free to be in contact with TA's.  Run the following commands to install dependencies before starting the notebook:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "PwJlcM67zK6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ec56b0d-8761-4c8f-dcd7-eac045765d21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install x11-utils > /dev/null 2>&1\n",
        "!pip install pyglet > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
        "!apt-get install xvfb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Vuzy-9Ky-adf"
      },
      "outputs": [],
      "source": [
        "!pip install pyvirtualdisplay > /dev/null 2>&1\n",
        "!pip install swig > /dev/null 2>&1\n",
        "!pip install stable-baselines3 \"gymnasium[all]\" pygame matplotlib seaborn numpy pandas > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsiukyCaeaIb"
      },
      "source": [
        "Hamid is CE student who loves learning about RL. He tried to use **Gymnasium** and **Stable-Baselines3** to solve games he played as a kid.  \n",
        "\n",
        "He started to list the games which was provided in gymnasium library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "iKSNMhzw1qIU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4151dd64-1863-42b0-9db9-bab951161250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gymnasium envs listed: ['Acrobot-v1', 'Ant-v2', 'Ant-v3', 'Ant-v4', 'Ant-v5', 'BipedalWalker-v3', 'BipedalWalkerHardcore-v3', 'Blackjack-v1', 'CarRacing-v3', 'CartPole-v0', 'CartPole-v1', 'CliffWalking-v0', 'FrozenLake-v1', 'FrozenLake8x8-v1', 'GymV21Environment-v0', 'GymV26Environment-v0', 'HalfCheetah-v2', 'HalfCheetah-v3', 'HalfCheetah-v4', 'HalfCheetah-v5', 'Hopper-v2', 'Hopper-v3', 'Hopper-v4', 'Hopper-v5', 'Humanoid-v2', 'Humanoid-v3', 'Humanoid-v4', 'Humanoid-v5', 'HumanoidStandup-v2', 'HumanoidStandup-v4', 'HumanoidStandup-v5', 'InvertedDoublePendulum-v2', 'InvertedDoublePendulum-v4', 'InvertedDoublePendulum-v5', 'InvertedPendulum-v2', 'InvertedPendulum-v4', 'InvertedPendulum-v5', 'LunarLander-v3', 'LunarLanderContinuous-v3', 'MountainCar-v0', 'MountainCarContinuous-v0', 'Pendulum-v1', 'Pusher-v2', 'Pusher-v4', 'Pusher-v5', 'Reacher-v2', 'Reacher-v4', 'Reacher-v5', 'Swimmer-v2', 'Swimmer-v3', 'Swimmer-v4', 'Swimmer-v5', 'Taxi-v3', 'Walker2d-v2', 'Walker2d-v3', 'Walker2d-v4', 'Walker2d-v5', 'phys2d/CartPole-v0', 'phys2d/CartPole-v1', 'phys2d/Pendulum-v0', 'tabular/Blackjack-v0', 'tabular/CliffWalking-v0']\n"
          ]
        }
      ],
      "source": [
        "from gymnasium import envs\n",
        "\n",
        "all_envs = envs.registry\n",
        "env_ids = [env_spec  for env_spec in all_envs]\n",
        "print(\"Gymnasium envs listed:\",sorted(env_ids))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVzichGh12ct"
      },
      "source": [
        "Then He selected Mountain Car Game to work with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "dVGRaUWo11hG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd226102-9164-4d90-be2d-9e45e9d46428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action Space Discrete(3)\n",
            "State Space Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n",
            "Action Example: 2\n",
            "State Example: [0.0783528  0.04977676]\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"MountainCar-v0\", render_mode=\"rgb_array\", goal_velocity=0.1)\n",
        "\n",
        "print(\"Action Space {}\".format(env.action_space))\n",
        "print(\"State Space {}\".format(env.observation_space))\n",
        "\n",
        "print(\"Action Example: {}\".format(env.action_space.sample()))\n",
        "print(\"State Example: {}\".format(env.observation_space.sample()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-QL4hvx0RPw"
      },
      "source": [
        "Hamid wanted to visualize the env for better understandig of gym envs. He had two options:\n",
        "\n",
        "\n",
        "1.   rendering inside the colab\n",
        "2.   rendering as video file\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP6zKPjw20V7"
      },
      "source": [
        "For ploting the game **inside** the colab he used **pyvirtualdisplay** package:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "pf1WFJOS2z5W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab69259f-76f5-4c3f-86d4-19b8ef7c08a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7d2568f28390>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "from pyvirtualdisplay import Display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxNakxbA40x8"
      },
      "source": [
        "So He started modify the code to learn how action works and plot it. He selected action of\n",
        "\n",
        " *`2: Accelerate to the right`*\n",
        "\n",
        "For every state of car."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Y_Q3way92dWf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "93fd01d8-a1b0-40b4-f058-92a4ab277a24"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAF7CAYAAAD4/3BBAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAATdVJREFUeJzt3XlYVPXiP/D3zMAMm4AoiwgoKooouCDiuKKgqOCKpeaWmt28aJZ+1ShbvLeyslwql7qVWup119TcUTETN5RUFFJTwVgVYdgHZj6/P7rOL1JLdODMwPv1POd5ZM6Zmfec0Hl3zud8jkwIIUBERERkQuRSByAiIiL6MxYUIiIiMjksKERERGRyWFCIiIjI5LCgEBERkclhQSEiIiKTw4JCREREJocFhYiIiEwOCwoRERGZHBYUIiIiMjmSFpRly5ahadOmsLKyQnBwME6fPi1lHCIiIjIRkhWUjRs3YubMmXj77bdx7tw5tGvXDuHh4cjOzpYqEhEREZkImVQ3CwwODkZQUBA+//xzAIBer4enpyemT5+O1157TYpIREREZCIspHhTrVaLhIQExMTEGB6Ty+UICwtDfHz8A9uXlZWhrKzM8LNer0dubi4aNGgAmUxWI5mJiIjo6QghUFBQAHd3d8jlf30SR5KCcufOHeh0Ori6ulZ63NXVFcnJyQ9sv2DBAsyfP7+m4hEREVE1SktLg4eHx19uI0lBqaqYmBjMnDnT8HN+fj68vLyQlpYGe3t7CZMRERHR49JoNPD09ES9evX+dltJCkrDhg2hUCiQlZVV6fGsrCy4ubk9sL1KpYJKpXrgcXt7exYUIiIiM/M4wzMkuYpHqVQiMDAQsbGxhsf0ej1iY2OhVquliEREREQmRLJTPDNnzsSECRPQqVMndO7cGUuWLEFRUREmTpwoVSQiIiIyEZIVlJEjRyInJwdvvfUWMjMz0b59e+zbt++BgbNERERU90g2D8rT0Gg0cHBwQH5+PsegEBERmYmqfH/zXjxERERkclhQiIiIyOSwoBAREZHJYUEhIiIik8OCQkRERCbHLKa6JyIiIuN71IW8pnAjXhYUIiKiOkqnu4ukpLawte0MG5vOsLUNgo1NR8hkSshkFpDJLP+31HxhYUEhIiKqo4QQqKjIQn7+LuTn7/rfoxawtg6AtXUAbGwCYG3tDwuLBlAoHAyLTFb99YEFhYiIiP6gAiUl51BScg65ub8/olQ2hVLZDCpVM6hU3lAqPWFp6QmlsjGUysaQy22MnoIFhYiIiP6SVnsTWu1NFBYeBgAoFPVhYeECCwtnWFo6Q6lsBiur1rCy8oW1tS8sLBo89XuyoBAREVGV6HT3oNPdQ1lZCgBAJlNCLreFXG4DudwWHh4fw9Fx0FO9BwsKERERVcnvA2dVkMlUkMtVUKl8YGsbDBubINjaBkGp9Hjq92BBISIior+kUDhCoXCChUV9KBROsLJqBWtrf1hbt4G1dVsoFA5Gf08WFCIiIvoDOZRKrz8snlAqvaFUNoFK1RRKZRPI5apqT8GCQkREVIfJZFawtm4DK6s2sLb2g5VVa1hYNIRC0QAWFk6wsGgAmazmJ55nQSEiIqqjNBrg3XfbY+PGHf8bT2L1v7ElnEmWiIiIJKLXA3fvKmFp6Sp1lAfwZoFERERkclhQiIiIyOSwoBAREZHJYUEhIiIik8OCQkRERCaHBYWIiIhMDgsKERERmRwWFCIiIjI5LChERERkclhQiIiIyOSwoBAREZHJYUEhIiIik8OCQkRERCbH6AXlnXfegUwmq7T4+voa1peWliI6OhoNGjSAnZ0doqKikJWVZewYREREZMaq5QhKmzZtkJGRYViOHz9uWPfqq69i165d2Lx5M+Li4pCeno7hw4dXRwwiIiIyUxbV8qIWFnBzc3vg8fz8fHz99ddYv349+vTpAwBYtWoVWrdujZMnT6JLly7VEYeIiIjMTLUcQbl69Src3d3RrFkzjBkzBqmpqQCAhIQElJeXIywszLCtr68vvLy8EB8f/8jXKysrg0ajqbQQERFR7WX0ghIcHIzVq1dj3759WLFiBW7cuIEePXqgoKAAmZmZUCqVcHR0rPQcV1dXZGZmPvI1FyxYAAcHB8Pi6elp7NhERERkQox+imfAgAGGPwcEBCA4OBhNmjTBpk2bYG1t/USvGRMTg5kzZxp+1mg0LClERES1WLVfZuzo6IiWLVvi2rVrcHNzg1arRV5eXqVtsrKyHjpm5T6VSgV7e/tKCxEREdVe1V5QCgsLcf36dTRq1AiBgYGwtLREbGysYX1KSgpSU1OhVqurOwoRERGZCaOf4vm///s/DBo0CE2aNEF6ejrefvttKBQKjB49Gg4ODpg8eTJmzpwJJycn2NvbY/r06VCr1byCh4iIiAyMXlBu376N0aNH4+7du3B2dkb37t1x8uRJODs7AwAWL14MuVyOqKgolJWVITw8HMuXLzd2DCIiIjJjMiGEkDpEVWk0Gjg4OCA/P5/jUYiIiJ5QTk4ORowYgbi4uBp5v6p8f/NePERERGRyWFCIiIjI5LCgEBERkclhQSEiIiKTUy03CyQiIiLzIYRAeXk5SktLoVAoIISAEAI6nQ5arRY2NjZQKBRQKBSQy+VQKBQAAJlMVm2ZWFCIiIjqiIqKCty9excZGRnIzMyERqNBTk4O1q5di/z8fPz2229wc3ODEAJ6vR6FhYVIS0uDn58fLC0tYWFhAZlMBpVKBUdHR8Ps7nZ2drC0tETTpk0N5eVpsaAQERHVUkVFRTh37hwSExOh0WiQlZUFlUoFrVaLgoICuLu7G25Bo1Kp0KJFC9jb2xuOlggh0Lx5c1hbW0Or1aKsrAylpaXQaDS4c+cOysvLodVqDbPGe3t7o0mTJmjevLnhz7a2tk+UnfOgEBER1RJCCJw7dw6XLl3CyZMncfPmTTg5OcHFxQVqtRoeHh6ws7ODjY0NlEolbGxskJ6ejjZt2lTpyIcQAiUlJYaluLgYeXl5KCkpwc2bN3Hz5k1cu3YNN2/eRLdu3RASEoKuXbsCwGN/f7OgEBERmaH740bKy8tx9+5d7Nq1Czt27EBeXh4GDBiAkJAQ+Pv7w9raGgqFApaWllAoFNU6bkQIgYqKCsNSUlKC48ePIzY2FqdPn4a3tzc2b97MgkJERFTb6PV63LlzBzdv3sThw4dx9epVpKamYsCAAYiMjETz5s0hl///i3Srs5A8jvs1Q6vV4scff0Tfvn0f6/ubY1CIiIjMQEFBAa5fv46ff/4Zt2/fRm5uLpydnfHSSy+hU6dOkheRR7mfS6VSoXPnzo/9PBYUIiIiE1ZcXIwDBw5g3759cHJyQpMmTdCzZ0+0adMGTk5OUserNiwoREREJub+aZG9e/di7dq1cHJywqBBg9CuXTu4uLhAqVRKnLD6saAQERGZiPtzj+zbtw//+c9/4OvrizfeeAMtWrSApaVlpbEltR0LChERkQnIyMjAhQsXsHv3blRUVGDJkiVo3bp1nSolf8SCQkREJKH09HT8+OOPuHr1KioqKjBhwgR06NDBaDOymisWFCIiIglotVocOHAAO3bsgJ+fH8LCwtChQweoVCqpo5kEFhQiIqIaJIRAUVER5s+fj4KCAowbNw6BgYGwtbU12UuFpcCCQkREVAMqKiqQn5+PQ4cOYenSpXjttdcwYMAAww34qDIWFCIiompWXl6O2NhYbN68Gc2aNcO+ffs4E/rfYEEhIiKqRrdu3cLGjRtRVlaGZ599FiEhIRxn8hhYUIiIiKqBEAL79u3DgQMH0LNnT3Tt2hWurq5SxzIbLChERERGJIRAWloa3nnnHTg4OCA6Ohre3t51/rLhqmJBISIiMpLy8nL8+uuv+OSTT9CuXTtER0dDoVBwEOwTYEEhIiIyguzsbMTFxeHw4cN44YUXqnTnXnoQCwoREdFTSklJwffffw9bW1v8+9//RsOGDaWOZPZYUIiIiJ6QXq9HbGwsNmzYgOeeew5du3aFtbW11LFqBRYUIiKiJ1BeXo61a9fi1KlT+PDDD1G/fn0OhDUiFhQiIqIq0Ov1yMrKwtdffw2VSoUVK1YAAAfCGhkLChER0WMqLS3FTz/9hLi4OLRv3x6DBg1iMakmLChERESPQa/X4/vvv8e+ffvwz3/+Ex06dICFBb9Gq4u8qk84duwYBg0aBHd3d8hkMuzYsaPSeiEE3nrrLTRq1AjW1tYICwvD1atXK22Tm5uLMWPGwN7eHo6Ojpg8eTIKCwuf6oMQERFVp88//xy//vor5s2bh6CgIJaTalblglJUVIR27dph2bJlD13/0Ucf4dNPP8XKlStx6tQp2NraIjw8HKWlpYZtxowZg6SkJBw8eBC7d+/GsWPH8OKLLz75pyAiIqoGQgiUlJTgzTffhEqlwiuvvILmzZtLHatOkAkhxBM/WSbD9u3bMXToUAC//4d0d3fHrFmz8H//938AgPz8fLi6umL16tUYNWoUrly5Aj8/P5w5cwadOnUCAOzbtw8DBw7E7du34e7u/rfvq9Fo4ODggPz8fN4NkoiIqoVOp8Mvv/yCdevWwd/fH8OGDYNSqZQ6llmryvd3lY+g/JUbN24gMzMTYWFhhsccHBwQHByM+Ph4AEB8fDwcHR0N5QQAwsLCIJfLcerUqYe+bllZGTQaTaWFiIiougghcPbsWSxcuBA9evTAiBEjWE5qmFELSmZmJgA8cLdGV1dXw7rMzEy4uLhUWm9hYQEnJyfDNn+2YMECODg4GBZPT09jxiYiIqrk6NGj2L17N8aPH4/w8HDObyIBoxaU6hITE4P8/HzDkpaWJnUkIiKqhYQQ2L59O44ePYopU6YgJCRE6kh1llGHILu5uQEAsrKy0KhRI8PjWVlZaN++vWGb7OzsSs+rqKhAbm6u4fl/plKpoFKpjBmViIiokvLycuzatQspKSmYNm0a76cjMaMeQfH29oabmxtiY2MNj2k0Gpw6dQpqtRoAoFarkZeXh4SEBMM2hw8fhl6vR3BwsDHjEBER/S0hBLRaLbZs2YJr167hhRdegLOzMydgk1iVj6AUFhbi2rVrhp9v3LiBxMREODk5wcvLC6+88greffdd+Pj4wNvbG2+++Sbc3d0NV/q0bt0a/fv3x5QpU7By5UqUl5dj2rRpGDVq1GNdwUNERGRsy5cvh0ajwcsvvwxHR0ep4xCeoKCcPXsWvXv3Nvw8c+ZMAMCECROwevVqzJkzB0VFRXjxxReRl5eH7t27Y9++fbCysjI8Z926dZg2bRpCQ0Mhl8sRFRWFTz/91Agfh4iI6PGVlZXhzTffRIcOHfDCCy/Azs5O6kj0P081D4pUOA8KERE9DSEEiouL8d5776Fnz54ICwvjzLA1oCrf3/yvQUREdYoQAvfu3cOqVasQFBSEfv36QS43i4ta6xQWFCIiqlOys7PxzTffwMPDA8OGDZM6Dj0CKyMREdUZ2dnZWLlyJdzc3DBu3Dip49Bf4BEUIiKqE7KysrB8+XL06tWr0sUeZJpYUIiIqFYTQuDu3bv4z3/+g9DQUHTv3p1znJgBFhQiIqq17peT9evXo3379ujRowfLiZlgQSEiolrr5s2b2LBhA5o1a4bIyEip41AVcJAsERHVSrm5uViyZAkaN26MkSNHSh2HqohHUIiIqNYpKCjAxx9/jMGDB6NPnz5Sx6EnwIJCRES1hhACpaWlWLZsGbp3746QkBCOOTFTLChERFRraLVarFu3Dg0bNsSAAQNYTswYx6AQEVGtoNfrsWbNGuTl5WHSpEksJ2aOR1CIiKhWWLRoEWQyGaZPn85769QCLChERGT2VqxYgXr16mHcuHFQqVRSxyEjYEEhIiKzpdPpsHPnTuh0Ojz33HOwtraWOhIZCY+BERGRWdLpdPjpp59w/fp1DB8+HA4ODhx3UouwoBARkdkRQuDs2bM4fvw4Bg8eDHd3d6kjkZGxoBARkdnZvXs3lixZgmHDhqFly5ZSx6FqwDEoRERkNoQQuHXrFrZs2YJ58+ahdevWUkeiasIjKEREZBaEEMjJycGnn36KOXPmwM/PT+pIVI14BIWIiMxCQUEB1qxZg9DQULRp00bqOFTNeASFiIhMnlarxfr16+Hi4oKwsDCp41AN4BEUIiIyeStXroRcLkdUVBQnYqsjWFCIiMhkCSHw3nvvITk5GStXroSdnZ3UkaiGsKAQEZFJ0ul0OHbsGEpKSrBixQqWkzqGY1CIiMjk6PV6JCUl4dixY5gyZQrq1asndSSqYSwoRERkcrKzs7F161YMGDAATZs2lToOSYAFhYiITIpWq8WSJUvQtWtXBAYGSh2HJMKCQkREJkOn02H+/Plo3749+vTpA4VCIXUkkggLChERmYSysjK8/vrryMjIwLPPPgtLS0upI5GEqlxQjh07hkGDBsHd3R0ymQw7duyotP7555+HTCartPTv37/SNrm5uRgzZgzs7e3h6OiIyZMno7Cw8Kk+CBERma/y8nIcOnQITk5O+OyzzyCX8/+f67oq/wYUFRWhXbt2WLZs2SO36d+/PzIyMgzLf//730rrx4wZg6SkJBw8eBC7d+/GsWPH8OKLL1Y9PRER1QoXL17E2bNnMWbMGNja2kodh0xAledBGTBgAAYMGPCX26hUKri5uT103ZUrV7Bv3z6cOXMGnTp1AgB89tlnGDhwID7++GO4u7tXNRIREZmx7OxsbNy4EaNGjULjxo2ljkMmolqOoR09ehQuLi5o1aoVpk6dirt37xrWxcfHw9HR0VBOACAsLAxyuRynTp166OuVlZVBo9FUWgBgw4YN0Ov11fERiIioBpSVlWHhwoUIDQ1FQEAAZDKZ1JHIRBi9oPTv3x/ffvstYmNj8eGHHyIuLg4DBgyATqcDAGRmZsLFxaXScywsLODk5ITMzMyHvuaCBQvg4OBgWDw9PQEAt27dwvHjxw2vTURE5iM/Px+ffPIJ/Pz80LdvX16xQ5UYvaCMGjUKgwcPhr+/P4YOHYrdu3fjzJkzOHr06BO/ZkxMDPLz8w1LWloaAGDo0KE4cuQIfv31VwghjPQJiIioupWVleGrr75CXl4eJkyYwCMn9IBqHybdrFkzNGzYENeuXQMAuLm5ITs7u9I2FRUVyM3NfeS4FZVKBXt7+0oLALRq1QrdunXD2rVreRUQEZEZOXz4MEpKSvD666/zih16qGr/rbh9+zbu3r2LRo0aAQDUajXy8vKQkJBg2Obw4cPQ6/UIDg6u8uv36tULfn5+WLJkCY+iEBGZgeTkZJw+fRrPPvssHBwcpI5DJqrKBaWwsBCJiYlITEwEANy4cQOJiYlITU1FYWEhZs+ejZMnT+LmzZuIjY3FkCFD0KJFC4SHhwMAWrdujf79+2PKlCk4ffo0fvrpJ0ybNg2jRo16oit4LC0tERUVBa1Wi8WLF6O8vLzKr0FERNVPCIG7d+9i06ZNCAkJQYsWLXhqhx6pygXl7Nmz6NChAzp06AAAmDlzJjp06IC33noLCoUCFy5cwODBg9GyZUtMnjwZgYGB+PHHH6FSqQyvsW7dOvj6+iI0NBQDBw5E9+7d8eWXXz7xh7CwsMC8efOQkJCALVu28MoeIiITVFZWhjVr1sDLyws9e/bkqR36SzJhhudFNBoNHBwckJ+fbxiPAvx+Omn58uUYNWoUAgICJExIRER/tnLlSuTl5eG1116TOgpJ5FHf3w9Tq+pro0aNEBERgT179iAjI0PqOERE9D9r165FYmIipk+fLnUUMhO1qqAoFAoEBQWhSZMm2Lp1K8rKyqSORERUpwkhcO7cOVy9ehWvvvoqbGxspI5EZqJWFRQAUCqVePbZZ5GZmYndu3dzPAoRkUSEEMjMzMT+/fvRr18/tGzZkoNi6bHVuoIC/H4k5d1338V///tfnDhxQuo4RER1Unl5ObZv3w43Nzd069aN5YSqpFYWlPvef/99fPXVVzh37pzUUYiI6hQhBHbu3ImcnByMHj1a6jhkhmp1QWnevDmef/557NmzB7dv35Y6DhFRnXH48GEkJCQgOjoaVlZWUschM1SrC4pCoUC3bt3g7e2NvXv3oqSkROpIRES1mhACZ86cwbJly/DPf/4TDRs2lDoSmalaXVCA32eaHTVqFC5fvoyzZ89yOnwiomqUm5uL1atX44033oCHh4fUcciM1fqCAvx+JGX27NnYuHEjkpKSpI5DRFQrFRcXY8eOHejatSvatm3LQbH0VOpEQQEAd3d3TJkyBd988w1u3rwpdRwiolpFp9Phxx9/xL179xAeHl7p9iZET6LOFBQACAgIwJAhQzB//nzk5ORIHYeIqNa4efMmtm7dipEjR3LcCRlFnSooMpkMarUaPXv2xLp16ziJGxGREVRUVODFF1/EG2+8AU9PT6njUC1RpwoK8Pug2cjISJSXlyMuLg46nU7qSEREZis/Px9z5szBnDlz4OXlJXUcqkXqXEGRyWRwdnZGeHg44uLicPPmTV7ZQ0T0BIqLi/HNN9/AysoKPXr04KBYMqo6V1DuCwgIQPfu3bF06VKe6iEiqiIhBM6ePYu8vDy8/PLLvAkgGV2dLSgA0Lt3bwQEBGDhwoVSRyEiMivZ2dnYs2cPhg0bBjc3N6njUC1UpwuKQqHAuHHjUFpaik2bNnE8ChHRY9BqtVixYgW6dOkCf39/qeNQLVWnCwoAKJVK/OMf/8C6desQGxvL8ShERH9Bp9Nh7dq1UKlUGDJkCBQKhdSRqJaq8wVFJpOhUaNGeP3113HixAlkZ2dLHYmIyGQdPXoUZ8+exdy5czkolqpVnS8o97Vr1w4tW7bEzp07eVNBIqKHOH78OL777jvMnDmT5YSqHQvK/1hZWSEyMhJpaWk4fvw4T/UQEf1BRkYG9u3bh6ioKDRt2pQFhaqdhdQBTIm9vT1ef/11hIeHo127dnBxcZE6EhGR5MrLy3HkyBG4uLhgwIABsLDgVwdVPx5B+RMrKyt8+eWXmDNnDsejEFGdJ4TA+fPncerUKUycOJHlhGoMC8pD+Pj4ICIiAh9//DHS09OljkNEJJnr169j3bp1mDp1KurVqyd1HKpDWFAeQi6XIzw8HHZ2djh48CDnRyGiOik/Px+ffPIJnnvuOfj6+kodh+oYFpRHsLe3x8SJE5GSkoLk5GQOmiWiOkUIgSVLliA0NBRBQUFSx6E6iAXlL3h4eCAiIgLr1q3DvXv3WFKIqE7Q6XT49ttvkZGRgV69evGKHZIEC8pfkMlk6NatG3x8fPDVV1+hoqJC6khERNVKCIHk5GQkJydj+vTpcHZ2ZkEhSbCgPIaJEyciNzcX27dvlzoKEVG1KikpwZYtW9CzZ0+0adNG6jhUh7GgPKZZs2YhMTERx48flzoKEVG1EEJg1apVcHZ2RmhoqNRxqI6rUkFZsGABgoKCUK9ePbi4uGDo0KFISUmptE1paSmio6PRoEED2NnZISoqCllZWZW2SU1NRUREBGxsbODi4oLZs2eb/OmThg0bYtCgQfjkk0/w888/czwKEdUqQggcPHgQ169fx4QJE6BUKqWORHVclQpKXFwcoqOjcfLkSRw8eBDl5eXo168fioqKDNu8+uqr2LVrFzZv3oy4uDikp6dj+PDhhvU6nQ4RERHQarU4ceIE1qxZg9WrV+Ott94y3qeqBjKZDF26dMHIkSMRFxeH0tJSqSMRERnNr7/+iq+//hr/+te/YGtrK3UcIsjEUxwKyMnJgYuLC+Li4tCzZ0/k5+fD2dkZ69evx4gRIwAAycnJaN26NeLj49GlSxfs3bsXkZGRSE9Ph6urKwBg5cqVmDt3LnJych6rtWs0Gjg4OCA/Px/29vZPGv+JaDQafP755wgMDERYWBhvNU5EZi8jIwMffvghRo4cieDgYMjlPPtP1aMq399P9VuYn58PAHBycgIAJCQkoLy8HGFhYYZtfH194eXlhfj4eABAfHw8/P39DeUEAMLDw6HRaJCUlPTQ9ykrK4NGo6m0SMXe3h6jRo3CwYMHHzi9RURkbgoKCrBx40Z4eHigTZs2LCdkMp74N1Gv1+OVV15Bt27d0LZtWwBAZmYmlEolHB0dK23r6uqKzMxMwzZ/LCf3199f9zALFiyAg4ODYfH09HzS2EbRrFkzTJw4EfPmzUNZWZmkWYiInpRer8elS5eQnp6OCRMm1PgRaaK/8sQFJTo6GpcuXcKGDRuMmeehYmJikJ+fb1jS0tKq/T3/jp+fHyZMmIC33noLer1e6jhERFVWWFiITz/9FP/4xz/g7OwsdRyiSp6ooEybNg27d+/GkSNH4OHhYXjczc0NWq0WeXl5lbbPysqCm5ubYZs/X9Vz/+f72/yZSqWCvb19pUVqMpkM/fr1g5ubG9avX88jKURkVoqKijB//nxMnDgRzZo1kzoO0QOqVFCEEJg2bRq2b9+Ow4cPw9vbu9L6wMBAWFpaIjY21vBYSkoKUlNToVarAQBqtRoXL15Edna2YZuDBw/C3t4efn5+T/NZapy1tTUiIyNx7NgxJCQk8NJjIjIL5eXlWL16NZo1a4a+fftyplgySRZV2Tg6Ohrr16/H999/j3r16hnGjDg4OMDa2hoODg6YPHkyZs6cCScnJ9jb22P69OlQq9Xo0qULAKBfv37w8/PDuHHj8NFHHyEzMxPz5s1DdHQ0VCqV8T9hNfPx8cGoUaNw+PBh+Pr6GgYMExGZqtjYWGRnZ2Pu3LksJ2SyqnQEZcWKFcjPz0dISAgaNWpkWDZu3GjYZvHixYiMjERUVBR69uwJNzc3bNu2zbBeoVBg9+7dUCgUUKvVGDt2LMaPH49//etfxvtUNaxbt25wc3PDpk2boNPppI5DRPRIiYmJ2LVrF4YPHw5ra2up4xA90lPNgyIVKedBeZSysjLMmDEDo0ePRq9evaSOQ0RUiRACubm5+OijjxAQEIBRo0ZxHieqcTU2Dwr9fyqVCp9//jnefvttpKenSx2HiKgSIQROnDgBS0tLPPfccywnZPJYUIxIoVDgww8/xPLlyx85pwsRkRTOnTuH/fv3Y8aMGRx3QmaBBcWIZDIZ2rdvj1atWuHbb781zLRLRCSlW7duYdWqVYiOjuZ8J2Q2WFCMTKVSISIiAnfv3sX58+eljkNEdZxOp8P777+PsWPHwtfXV+o4RI+NBaUa1K9fHxMmTMDOnTvx22+/cX4UIpJERUUF1qxZg6CgIHTo0IGndsissKBUA5lMBj8/P4SEhOCLL75AcXGx1JGIqI7R6XSIi4tDUlISQkNDYWVlJXUkoiphQalGgwcPhqOjI7755hupoxBRHZObm4tNmzYhMjLygVm/icwBC0o1e+mll5Ceno79+/dLHYWI6gi9Xo9Vq1ZBrVYjJCRE6jhET4QFpZpZW1tj8uTJ+PHHH5GSksLxKERUrYQQ2LJlC0pKSjBy5EiOOyGzxYJSzWQyGZo3b44uXbpgzZo1uHfvntSRiKgW+/nnn7Fr1y7MnTuXU9mTWWNBqQEymQy9e/eGtbU1Dh8+jIqKCqkjEVEtlJ2djS+//BJvvvmmWd58leiPWFBqiK2tLSZOnIjz58/j/PnzPNVDREaVl5eHTZs2oU+fPmjSpAlP7ZDZY0GpQR4eHhg3bhwWL17MWWaJyGjKy8uxe/duZGRkIDQ0lEdPqFZgQalhvr6+mDJlCubMmQO9Xi91HCIyc0II3Lt3D7t27cLUqVNRv359qSMRGQULigS6d++Ojh07YvXq1SgvL5c6DhGZsaKiIrz99tuYMWMGGjduLHUcIqNhQZGApaUlhg0bhvT0dJw6dYpHUojoiZSWlmLlypXo3LkzunbtynEnVKuwoEjE1dUVISEh2Lp1K3777Tep4xCRGdq9ezdKS0sxduxYqaMQGR0LioQCAwPRrl07bNmyBVqtVuo4RGRGzp8/j8uXL2Ps2LGwsLCQOg6R0bGgSMja2hqjRo1CTk4O9u/fz0uPiehvCSGQnZ2NgwcPonv37vDy8uKpHaqVWFAkZmVlhXfffRefffYZrl+/LnUcIjJx5eXl+O6771BSUoLevXtDLuc/41Q78TfbBMhkMixduhSffvopbt++LXUcIjJhZ86cQWpqKmbOnMkjJ1SrsaCYAJlMBh8fH4SFhWHbtm3Iy8uTOhIRmaArV65gw4YNePnll1GvXj2p4xBVKxYUE2FhYYHQ0FBUVFTgyJEjvPSYiCopKCjAokWLMGnSJDRv3lzqOETVjgXFhNja2iI8PBxr167FlStXOGiWiAAAOp0OK1asQHh4OPz9/aWOQ1QjWFBMjJ+fH1555RWsWbMG9+7dkzoOEUmsoqICsbGxsLCwQO/evaFQKKSORFQjWFBMjEwmQ48ePRAQEIDPP/8cFRUVUkciIokIIZCcnIyjR48iPDwcDRo04MBYqjNYUEzUmDFjAAAbNmyQOAkRSaW8vBxffPEFOnfujDZt2kgdh6hGsaCYsBdffBHXrl3DiRMnOB6FqI4RQmD58uXw8/PDwIEDpY5DVONYUEyUTCaDq6srBg0ahEOHDuG3335jSSGqI/R6Pfbv34+0tDRMnjwZSqVS6khENY4FxYTJZDIEBgbC3d0dmzdvRklJidSRiKgGpKSkYMeOHXjjjTdYTqjOYkExA5GRkUhNTcWhQ4d4FIWolsvKysL27dsxduxYODo6Sh2HSDJVKigLFixAUFAQ6tWrBxcXFwwdOhQpKSmVtgkJCYFMJqu0vPTSS5W2SU1NRUREBGxsbODi4oLZs2fzapW/4ObmhpkzZyI2NhYXLlyQOg4RVZOSkhLs27cPHh4e6NixI++zQ3ValX774+LiEB0djZMnT+LgwYMoLy9Hv379UFRUVGm7KVOmICMjw7B89NFHhnU6nQ4RERHQarU4ceIE1qxZg9WrV+Ott94yzieqpTw9PTFr1izMmzcPBQUFUschIiMTQuDw4cM4duwYhg4dChsbG6kjEUlKJp7inEFOTg5cXFwQFxeHnj17Avj9CEr79u2xZMmShz5n7969iIyMRHp6OlxdXQEAK1euxNy5c5GTk/NY51s1Gg0cHByQn58Pe3v7J41vdoQQOHr0KPbs2YN3330XKpVK6khEZCS5ubkYOXIk1q5da/i3kai2qcr391MdP8zPzwcAODk5VXp83bp1aNiwIdq2bYuYmBgUFxcb1sXHx8Pf37/SX8Dw8HBoNBokJSU99H3Kysqg0WgqLXWRTCZD586d4ePjgx07dqCsrEzqSERkBDk5OZg/fz7+/e9/s5wQ/c8TFxS9Xo9XXnkF3bp1Q9u2bQ2PP/fcc1i7di2OHDmCmJgYfPfddxg7dqxhfWZm5gN/Ae//nJmZ+dD3WrBgARwcHAyLp6fnk8Y2e7a2thg4cCCuXr2K8+fP86aCRGausLAQ3333Hbp27YrOnTtLHYfIZFg86ROjo6Nx6dIlHD9+vNLjL774ouHP/v7+aNSoEUJDQ3H9+vUnvgNnTEwMZs6cafhZo9HU6ZLi4eGB3r17Y8WKFWjZsuUDR7CIyHzs3r0blpaWGDRoEAfFEv3BE/1tmDZtGnbv3o0jR47Aw8PjL7cNDg4GAFy7dg3A71ekZGVlVdrm/s9ubm4PfQ2VSgV7e/tKS13XuXNnDB48GAsXLuRRFCIzJITAxYsXkZycjEGDBsHa2lrqSEQmpUoFRQiBadOmYfv27Th8+DC8vb3/9jmJiYkAgEaNGgEA1Go1Ll68iOzsbMM2Bw8ehL29Pfz8/KoSp06ztLTEsGHD4OTkhFWrVvEybSIzIoRARkYGNm3ahNDQUDRp0oQ3AST6kyoVlOjoaKxduxbr169HvXr1kJmZiczMTMMMp9evX8e///1vJCQk4ObNm9i5cyfGjx+Pnj17IiAgAADQr18/+Pn5Ydy4cfj555+xf/9+zJs3D9HR0bwqpYrkcjlmzJiB5ORkHD58WOo4RPSY9Ho93nvvPdjZ2aFHjx4sJ0QPUaXLjB/1l2jVqlV4/vnnkZaWhrFjx+LSpUsoKiqCp6cnhg0bhnnz5lU6LXPr1i1MnToVR48eha2tLSZMmIAPPvgAFhaPNySmrl5m/DBCCNy6dQtffvklxo4dy6NQRGZg3bp1uHLlCt59912poxDVqKp8fz/VPChSYUGprKKiAseOHcP58+cxfvx4ODs7Sx2JiB7h0KFDiIuLw6uvvsoB7lTn1Ng8KGQaLCws0L17d8jlcmzduhVarVbqSET0J0IIXL16FUeOHMG4ceNQv359qSMRmTQWlFpCqVTilVdewdGjR3Hq1CneVJDIxOTn52Pr1q3o1asXfHx8OO6E6G+woNQiMpkMn376KVavXo3Lly9LHYeI/qe8vBw//PADbGxs0KtXL5YTosfAglLLuLi4YPr06Vi3bh1+/fVXqeMQ1XlCCKxbtw5Hjx7FyJEjebUi0WNiQamF/P39ERISgg0bNtTZ+xYRmYqrV6/ihx9+wOzZs3mfHaIqYEGphRQKBUJCQuDg4IBdu3ZxplkiiRQVFWHmzJlYsmQJWrZsKXUcIrPCglJLWVpa4plnnkFSUhKOHz/OkkJUwwoLC7Fo0SLMmDHjkbfxIKJHY0GppWQyGVxcXBAZGYkvvvgCSUlJUkciqjNKS0uxd+9euLu7o0uXLlAoFFJHIjI7LCi1XNeuXTFp0iQsWrQI+fn5UschqvX0ej0SExORnJyMAQMGoF69elJHIjJLLCh1QJ8+fTBy5Ei8/fbbnB+FqJqVlZXh3Xffxfjx4+Hu7i51HCKzxYJSR4SEhKBt27ZYvXo173xMVE1KS0sRFRWFl19+GV5eXlLHITJrLCh1gEwmg5WVFSIiInDnzh3Ex8dDp9NJHYuoVtFoNFiyZAkmTZqEvn37cjI2oqfEglKHNGrUCP3798ehQ4dw69Ytnu4hMpLS0lLs2rUL9evXR2RkJMsJkRGwoNQx/v7+6NatG9555x0eRSEyAiEETp06hZs3b2LEiBGwsrKSOhJRrcCCUgf17t0bAwcOxOuvv86jKERPQQiB9PR07NixA8888wwaNGggdSSiWoMFpQ6ytLTEiBEj0LRpU3z11VcoLy+XOhKRWbp37x4WLFiA4cOHw8fHR+o4RLUKC0odZWFhgTFjxiA3NxdHjhxhSSGqIo1Gg9mzZ8PZ2Rk9evTguBMiI2NBqcMcHBzw7LPPIj4+HikpKTzdQ/SYtFotvvvuOwQGBuLNN9+UOg5RrcSCUsd5e3ujf//++PbbbznTLNFj2rVrF7RaLSZMmAC5nP+MElUH/s0idOrUCW3atMG0adN4ZQ/RXxBC4Ny5c0hKSsKIESNgY2MjdSSiWosFhaBQKDBu3Di0atUK77zzDkpLS6WORGRyhBD47bffsH37dkRGRsLDw4PjToiqEQsKAQDkcjliYmJQr149fP/99ygrK5M6EpFJycrKwrJly9ClSxd07NiR5YSomrGgkIGFhQWmTJmCGzdu4NixYxw0S/Q/JSUl+PDDD9GiRQtERERIHYeoTmBBoUrq16+PZ599FnFxcfjll1+kjkNkEj7//HMEBATg+eeflzoKUZ3BgkIPaNq0KYYOHYoVK1bg3r17Uschkoxer8e2bdtgZWWFqKgoXrFDVIP4t40eIJfLERgYiODgYMyePRt3796VOhJRjdPr9Th79iySk5MxbNgw1KtXj+NOiGoQCwo9lEwmw+jRo9GyZUssWbKEc6RQnSKEwLVr17B3714MHDiQV+wQSYAFhf7Sq6++Cm9vb2zatImXH1OdkZqaik8++QT9+vVD+/btpY5DVCexoNBfsrS0xMiRI1FUVIS9e/fyyh6q9YqLizF37lxMmDABarVa6jhEdRYLCv0tW1tbjBs3Dj/99BMuXLjAkkK1Vnl5Od59911MnjwZXbp0kToOUZ1WpYKyYsUKBAQEwN7eHvb29lCr1di7d69hfWlpKaKjo9GgQQPY2dkhKioKWVlZlV4jNTUVERERsLGxgYuLC2bPno2KigrjfBqqNk5OTpg2bRqWL1+O5ORkqeMQGV1paSnWr1+PVq1a8e7ERCagSgXFw8MDH3zwARISEnD27Fn06dMHQ4YMQVJSEoDfxyvs2rULmzdvRlxcHNLT0zF8+HDD83U6HSIiIqDVanHixAmsWbMGq1evxltvvWXcT0VGJ5PJ0LRpU4wdOxbvv/8+zp07J3UkIqOpqKjAgQMHkJ+fj8jISFhZWbGgEElMJp7yeL2TkxMWLlyIESNGwNnZGevXr8eIESMAAMnJyWjdujXi4+PRpUsX7N27F5GRkUhPT4erqysAYOXKlZg7dy5ycnKgVCof6z01Gg0cHByQn58Pe3v7p4lPVSSEwL59+3Ds2DFMmTIFzZo1kzoS0VM7cOAAzp49i+effx7u7u5SxyGqtary/f3EY1B0Oh02bNiAoqIiqNVqJCQkoLy8HGFhYYZtfH194eXlhfj4eABAfHw8/P39DeUEAMLDw6HRaAxHYR6mrKwMGo2m0kLSkMlk6NevH/r164ctW7YgJyeHY1LIbAkh8MMPP+CLL77A5MmTWU6ITEiVC8rFixdhZ2cHlUqFl156Cdu3b4efnx8yMzOhVCrh6OhYaXtXV1dkZmYCADIzMyuVk/vr7697lAULFsDBwcGweHp6VjU2GZFCoUDPnj3RpEkTbN26FUVFRSwpZHb0ej3Onz+P9evXY9myZXBxcZE6EhH9QZULSqtWrZCYmIhTp05h6tSpmDBhAi5fvlwd2QxiYmKQn59vWNLS0qr1/ejvKRQKw+XHW7ZsgV6vlzoS0WMTQuDGjRvYvn073nzzTbi5uXHMCZGJqXJBUSqVaNGiBQIDA7FgwQK0a9cOS5cuhZubG7RaLfLy8iptn5WVBTc3NwCAm5vbA1f13P/5/jYPo1KpDFcO3V/INMyaNQtXrlzBt99+K3UUosd2584drF27Fv3794evr6/UcYjoIZ56HhS9Xo+ysjIEBgbC0tISsbGxhnUpKSlITU01THakVqtx8eJFZGdnG7Y5ePAg7O3t4efn97RRSCJvvPEG0tLS8OWXX0odhehvlZeX44MPPoBarUbXrl2ljkNEj1ClghITE4Njx47h5s2buHjxImJiYnD06FGMGTMGDg4OmDx5MmbOnIkjR44gISEBEydOhFqtNkx41K9fP/j5+WHcuHH4+eefsX//fsybNw/R0dFQqVTV8gGp+tWrVw/R0dEoLS3Ftm3bOB6FTJYQAtOmTcPAgQMRGhrK0zpEJqxKBSU7Oxvjx49Hq1atEBoaijNnzmD//v3o27cvAGDx4sWIjIxEVFQUevbsCTc3N2zbts3wfIVCgd27d0OhUECtVmPs2LEYP348/vWvfxn3U1GNkslkcHJywsiRI3H16lX8+OOP0Ol0UsciqqS4uBiTJk2Cj48PevfuDYVCIXUkIvoLTz0PihQ4D4rpunHjhuHcfqdOnfh/qGQS8vPzsWnTJjg6OmLIkCGPPecSERlXjcyDQvQw3t7eeOaZZ7Bz50789NNPUschE1NRUYH9+/fj4MGDNfaexcXF2LlzJ2xsbBAeHs5yQmQmWFDI6Hx9fTF69GisWLECu3btkjoOmYiEhASMHj0aU6dOxdSpUxEXF1ft76nX67F+/XqUl5cjIiKCR1yJzAgLClWL1q1bIyYmBmfPnuUdkOsoIQT0ej1u376NyZMnY9CgQdi6dStu3LiB69ev4+TJkygtLa2299fr9Vi9ejUKCwsxcuTIByaRJCLTZiF1AKqdZDIZ2rRpY5hKXKVSwcfHB3I5O3FdoNPpcOfOHWzcuBEzZ86EXq9/oKS+/vrr6N27N4KCgow+VqmkpARffPEFkpKSsHz5clhaWhr19Ymo+vHbgqqNTCaDv78/evXqhZ07d+LatWs8klLLCSGQnp6OLVu2YPTo0ZgxYwZ0Ot1D/7vr9XosW7YMFRUVRs1QXFyMPXv2oKSkBB999BHLCZGZ4hEUqnb3J+rbuHEj+vXrh+DgYIkTUXW4Pxh1y5YtOHDgAAoKCv72Od9++y1atmyJN954wygZtFotDh06hNzcXEyaNAn169c3yusSUc3jERSqEWq1GoMGDcInn3xSabZhqh1iY2MxePBgvPrqq9i6detjlZP7PvvsswdukfEkhBD4/vvvcevWLQwZMuSBG5MSkXlhQaEa065dO7zxxhs4cuQIkpOTebrHjAkhUFFRgcuXL6N///4YMWIEYmNj//Ku5I+Sk5ODf/zjH091w8mKigqsXbsWv/zyCyZNmsQ7ExPVAjzFQzVGJpMhICAAOp0O27dvx7Bhw9CyZUsOnDUzWq0WaWlp+OKLL/Dxxx8/ddHU6/W4ePEizp49i86dO1f5+UVFRfj888+Rl5eH+fPnc54TolqCBYVqlEwmQ8eOHVFWVobvv/8e/fv3R7t27aSORY9Bp9Ph+vXriI2NxZdffonExESjvfaVK1fw9ddfw9fXt0pzlRQWFmLnzp3Q6/WYNWsWywlRLcKCQpJQq9WwsrLC7t27kZ6ejgEDBkgdif5Cbm4u/vvf/2Lbtm346aefUFZWZvT32LNnD5555hn06dPnsY6qabVabN68GQAwefJkNGzY0OiZiEg6LCgkmfbt28Pa2hofffQRhBAYOHCg1JHoT4QQ2LRpExYtWoRffvnFKINZH+X27duYNm0aYmNj0bhx47/dfvHixXBzc8OQIUM4CRtRLcSCQpKRyWRo1aoV5syZg//85z+ws7ND9+7dOSZFYkIIlJWVISEhAdHR0bh69SqKi4uf+nUtLS3Rvn17tG7dGg0bNoQQAnfu3EFSUhIuXLiAiooKpKSkIC4uDqNHj37k5G2lpaV499130aZNG0RFRfG0DlEtxbsZk+SEEEhNTcVXX32FPn36oFevXiwpEikuLsaVK1ewePFirFu3ziivKZfL0aRJE/Tv3/+RV9f89ttvOHDgAG7fvg2ZTIb09PSHbnvv3j289957aNOmDcaOHctJ2IjMDO9mTGZFJpOhSZMmhhvIbdu2TepIdU55eTnOnTuHjz/+GCNHjjRaOQGARo0aoX///nB1dYVMJnvo4uHhgfDwcDg7O0Ov12PBggWVXkMIgYyMDHz11Vfw9fXF8OHDWU6IajkeQSGTkpeXh++++w6lpaX45z//CVtbW6kj1XqpqalYtWoVdu3ahfPnzz/VfCR/Zm9vj+HDh6Np06aPtf3169dx9+5djB07FqNHjzY8fuvWLSxduhT9+/dHSEgIT+sQmamqfH+zoJBJEUKguLgYGzduRFpaGmbMmAEHBwej30yOfvfrr79i0KBBuHnzplHGmfyRTCZD165d0bdv3yo9r2PHjoiIiIBcLocQApcuXcInn3yCuXPnwtfXl78LRGaMp3jIbMlkMtjY2GD8+PHw8fHBihUrkJOTw1lnq4m9vT3atWtn9HICABYWFujdu3eVn3fx4kUAv88Ou3HjRnz00Ud4//33WU6I6hgWFDI5MpkMFhYWeO6559CyZUssX74c165dkzpWrdSwYUOMHj262i7TVSgUVX5ORUUFtFotDhw4gGPHjmHOnDlwd3dnOSGqY1hQyKRFRUWhT58+WLduHW8yWE26dOmCfv36SR3DQAiB1atX45dffsHcuXPh7+8vdSQikgDnQSGT16NHD9SvXx9r1qxBVlYWhg8fDisrK6lj1RrOzs545pln8OOPPyIjI+Nvt/f09IS3tzccHR0hk8mg0Whw+/ZtXL161WiZ6tWrh2effRZOTk5Ge00iMi8cJEtmQa/X47fffsOqVavQsGFDTJo0iSXFiEpKShAWFoYTJ048chtbW1v07NkTrVq1go2NDSwsLCCTyVBRUYHS0lLcvn0bBw4cwL179wD8Pv9JZGQkOnbsWKUsQUFBCAsL45U6RLUQB8lSrSOXy+Hh4YHXX38dOp0O7733nuGLkJ6etbU1Fi1ahHr16j10va2tLfr27YugoCA4ODhAqVRCLpdDJpPB0tISdnZ28PX1xdChQw33xLGxsUFaWlqViqSVlRXUajXnOCEiFhQyH/cHz06fPh1BQUF47733cO7cuWq5cV1dFBwcjKCgoAcel8vlaNeuHdq3b28oJX92f8K1Jk2aQK1Wo0ePHvjss8+QkJCAIUOGwMbG5m/f387ODs8++yzq16/PAbFExFM8ZJ70ej3Onj2LDRs2IDAwEEOGDIGdnZ3UscxecnIyWrduXemxpk2b4vnnn6/S6/Tv3x+dOnWCQqFAaWkpEhMTceLECRQUFDx0ewcHB3Tv3h3+/v5QqVRPGp+ITBxP8VCtJ5fL0alTJ0yfPh13797Fp59+itLSUqljmb1mzZph5syZlR6r6kRrAHDq1ClotVoAv5+26dixI4YPH46OHTvCyckJCoUCQgg4OTkhKCgIw4cPR0BAAMsJERmwoJDZksvl8Pb2xqRJk9CmTRsMHjwY169fN+pU7XWNpaUlRowYUelmjc7OzlV+nXv37lX676BUKtG0aVOEhITA0tISx48fR9++fTFhwgSEhobCy8uLg2KJqBIWFDJ7dnZ2GDRoEL7++mu8/vrrWL9+PQoLCzn77BOQyWQIDAzE+++/b9TX1ev1yMrKwuLFi5GWloatW7eia9eusLe351ETInoozoNCtYJcLoenpycWL16MhQsXIjU1FcOHD0fLli0rHQ2gv6dUKtG+fXt4eXkhNTX1qV8vNzcXp0+fxoEDB9CtWzdERUUZISUR1Xb8l5tqFXd3d8TExMDT0xMbNmzAtm3bpI5klsLCwhAaGgrg9xsKVpWHhwcUCgWysrKwdOlSHDp0CJMmTcKwYcOMHZWIaqkqFZQVK1YgICAA9vb2sLe3h1qtxt69ew3rQ0JCDJcb3l9eeumlSq+RmpqKiIgI2NjYwMXFBbNnz0ZFRYVxPg0RABcXF4wbNw7PPfcc0tLS8I9//MOos5zWBQqFArNmzUKLFi2eaAxKcHAw4uLiMGPGDDRr1gyzZs1C27ZteTSLiB5blS4z3rVrFxQKBXx8fCCEwJo1a7Bw4UKcP38ebdq0QUhICFq2bIl//etfhufY2NgYLiXS6XRo37493NzcsHDhQmRkZGD8+PGYMmVKlc558zJjehxCCBQXFyM+Ph5LlizByy+/jN69extmQKW/l5OTAysrK9y+fRubN2/+23E9Qgh06NABZ86cQWFhIWJiYlC/fn0OgCUiAFX7/n7qeVCcnJywcOFCTJ48GSEhIWjfvj2WLFny0G337t2LyMhIpKenw9XVFQCwcuVKzJ07Fzk5OY/9jxgLCj2u+7/eZ8+exfvvv48OHTpg3LhxaNy4Mb80q6C0tBTHjx/HmTNnDJcP/5kQAvfu3cONGzcwYsQIjBo1ivuYiCqpkXlQdDodNmzYgKKiIqjVasPj69atQ8OGDdG2bVvExMSguLjYsC4+Ph7+/v6GcgIA4eHh0Gg0SEpKeuR7lZWVQaPRVFqIHsf9U41BQUHYvn07/Pz8sHTpUmzZsgW3b9+WOp7ZsLKyQrdu3RASEgJPT0/Y2NgYZpW1srKCVqtFTk4OLCwsMHfuXIwfP57lhIieSpWv4rl48SLUajVKS0thZ2dn+EcfAJ577jk0adIE7u7uuHDhAubOnYuUlBTDQMXMzMxK5QSA4efMzMxHvueCBQswf/78qkYlekBUVBSCgoKwe/dufPLJJ+jWrRsGDRrES10fg7W1NdRqNXx8fJCVlYXi4mLcuHEDu3fvho+PD8LDw9G9e3fegZiIjKLKp3i0Wi1SU1ORn5+PLVu24KuvvkJcXJyhpPzR4cOHERoaimvXrqF58+Z48cUXcevWLezfv9+wTXFxMWxtbbFnzx4MGDDgoe9ZVlZW6X4rGo0Gnp6ePMVDT6y4uBiXLl3CoUOHkJycjJdffhmdOnWSOpbZKCkpwapVq3D69GkMHjwYwcHBcHd359geIvpLVTnFU+UjKEqlEi1atAAABAYG4syZM1i6dCm++OKLB7YNDg4GAENBcXNzw+nTpyttk5WVBQBwc3N75HuqVCr+Hy4ZlY2NDYKCguDv74+UlBQsWrQIjRs3xgsvvAAvLy8OpH0IvV4PrVaLU6dOYdGiRWjatCnmzJmDli1bwsKCUyoRkXE99b8qer3+kXeTTUxMBAA0atQIAKBWq/Hee+8hOzsbLi4uAICDBw/C3t7+oUdgiKqTTCaDtbU12rVrhy+++AJbt27F1KlTERERgfDwcHh5eT3WXXhrO71ejzt37uDy5cv44YcfUFRUhA8++AC+vr4AwCJHRNWiSqd4YmJiMGDAAHh5eaGgoADr16/Hhx9+iP3796NZs2ZYv349Bg4ciAYNGuDChQt49dVX4eHhgbi4OAD//zJjd3d3fPTRR8jMzMS4cePwwgsv8DJjMgkXL17EwYMHkZWVhSZNmqBDhw7w9/evs3dKTk9Px6lTp3DixAkUFRUhKioK3bt35xFNInoi1XaZ8eTJkxEbG4uMjAw4ODggICAAc+fORd++fZGWloaxY8fi0qVLKCoqgqenJ4YNG4Z58+ZVCnHr1i1MnToVR48eha2tLSZMmIAPPvigSoeIWVCouqWmpuLkyZO4fPkycnNzER4ejv79+0OhUEgdrUakp6djx44duHnzJho1aoSWLVuiY8eOhqOhRERPokbnQZECCwrVBJ1Oh5ycHMTGxuLs2bO4dOkSnn/+eURERMDBwQFA7Ti98cd/An799Vd89tlnuHHjBiIjI9G1a1d4eXmhXr16EiYkotqCBYXIiHQ6HcrLy3Hnzh18+eWXOH36NFq1aoVp06ahUaNGsLKyMstBokIIlJaWorS0FImJifjuu++QlpaG/v37Y8yYMWjQoAEHCxORUbGgEFWj9PR0fP755zhz5gwCAgIQFBQEX19f1K9fH40bNzbpsnJ/+v/MzExkZmbi4MGDOH36NLy8vDB69Gh069bNpPMTkXljQSGqAeXl5Th9+jROnjyJ7OxsZGdno3Xr1mjdujV8fHzQpEkTWFtbSx0TAHD37l1cvHgRN27cQE5ODgoLCw1jxXr16oUOHTpIHZGI6gAWFKIadP8y3PPnzxuKSmZmJgoLC2FtbY2QkBAEBATAw8OjRo5OCCFQXl6OxMREJCcnIzExEcXFxSgqKoKPjw86duyI5s2bw9vbGyqViqdwiKjGsKAQSUQIgYKCAmg0Gty5cwcbN25EUVERfv31V+Tn58PPzw/29vbo06cPWrVqhUaNGlW6ZPdxy8If/9pqtVpcvnwZV69exeXLl5GUlISrV6/Cy8vLcHTE09MT1tbWcHR05IBXIpIMCwqRCRBCQKfTQQgBvV6P/Px8/Pzzz1i/fj20Wi0yMjJw9+5d1K9fH2VlZWjTpg1cXFxgZ2cHOzs7ZGVlwc3NDUqlEuXl5SgvL0dSUhKUSiVKS0uRnZ2NrKws5Ofnw9PTE0FBQWjTpg3atGmDli1bQqlUQi6XG27qxyMlRCQ1FhQiM6HVapGVlYWTJ0/CwsICOp0ORUVFKCwsREpKCpycnODg4ABLS0tYWFggMzMT3t7eaNasGZydneHs7AxHR0dDCSEiMmXVei8eIjIepVIJT09PeHp6Sh2FiMikyKUOQERERPRnLChERERkclhQiIiIyOSwoBAREZHJYUEhIiIik8OCQkRERCaHBYWIiIhMDgsKERERmRwWFCIiIjI5LChERERkclhQiIiIyOSwoBAREZHJYUEhIiIik8OCQkRERCaHBYWIiIhMDgsKERERmRwWFCIiIjI5LChERERkclhQiIiIyOSwoBAREZHJYUEhIiIik8OCQkRERCaHBYWIiIhMDgsKERERmRwWFCIiIjI5FlIHeBJCCACARqOROAkRERE9rvvf2/e/x/+KWRaUgoICAICnp6fESYiIiKiqCgoK4ODg8JfbyMTj1BgTo9frkZKSAj8/P6SlpcHe3l7qSGZLo9HA09OT+9EIuC+Nh/vSOLgfjYf70jiEECgoKIC7uzvk8r8eZWKWR1DkcjkaN24MALC3t+cvixFwPxoP96XxcF8aB/ej8XBfPr2/O3JyHwfJEhERkclhQSEiIiKTY7YFRaVS4e2334ZKpZI6ilnjfjQe7kvj4b40Du5H4+G+rHlmOUiWiIiIajezPYJCREREtRcLChEREZkcFhQiIiIyOSwoREREZHLMsqAsW7YMTZs2hZWVFYKDg3H69GmpI5mcY8eOYdCgQXB3d4dMJsOOHTsqrRdC4K233kKjRo1gbW2NsLAwXL16tdI2ubm5GDNmDOzt7eHo6IjJkyejsLCwBj+F9BYsWICgoCDUq1cPLi4uGDp0KFJSUiptU1paiujoaDRo0AB2dnaIiopCVlZWpW1SU1MREREBGxsbuLi4YPbs2aioqKjJjyKpFStWICAgwDDJlVqtxt69ew3ruQ+f3AcffACZTIZXXnnF8Bj35+N55513IJPJKi2+vr6G9dyPEhNmZsOGDUKpVIpvvvlGJCUliSlTpghHR0eRlZUldTSTsmfPHvHGG2+Ibdu2CQBi+/btldZ/8MEHwsHBQezYsUP8/PPPYvDgwcLb21uUlJQYtunfv79o166dOHnypPjxxx9FixYtxOjRo2v4k0grPDxcrFq1Sly6dEkkJiaKgQMHCi8vL1FYWGjY5qWXXhKenp4iNjZWnD17VnTp0kV07drVsL6iokK0bdtWhIWFifPnz4s9e/aIhg0bipiYGCk+kiR27twpfvjhB/HLL7+IlJQU8frrrwtLS0tx6dIlIQT34ZM6ffq0aNq0qQgICBAzZswwPM79+Xjefvtt0aZNG5GRkWFYcnJyDOu5H6VldgWlc+fOIjo62vCzTqcT7u7uYsGCBRKmMm1/Lih6vV64ubmJhQsXGh7Ly8sTKpVK/Pe//xVCCHH58mUBQJw5c8awzd69e4VMJhO//fZbjWU3NdnZ2QKAiIuLE0L8vt8sLS3F5s2bDdtcuXJFABDx8fFCiN/LolwuF5mZmYZtVqxYIezt7UVZWVnNfgATUr9+ffHVV19xHz6hgoIC4ePjIw4ePCh69eplKCjcn4/v7bffFu3atXvoOu5H6ZnVKR6tVouEhASEhYUZHpPL5QgLC0N8fLyEyczLjRs3kJmZWWk/Ojg4IDg42LAf4+Pj4ejoiE6dOhm2CQsLg1wux6lTp2o8s6nIz88HADg5OQEAEhISUF5eXmlf+vr6wsvLq9K+9Pf3h6urq2Gb8PBwaDQaJCUl1WB606DT6bBhwwYUFRVBrVZzHz6h6OhoREREVNpvAH8nq+rq1atwd3dHs2bNMGbMGKSmpgLgfjQFZnWzwDt37kCn01X6ZQAAV1dXJCcnS5TK/GRmZgLAQ/fj/XWZmZlwcXGptN7CwgJOTk6GbeoavV6PV155Bd26dUPbtm0B/L6flEolHB0dK2375335sH19f11dcfHiRajVapSWlsLOzg7bt2+Hn58fEhMTuQ+raMOGDTh37hzOnDnzwDr+Tj6+4OBgrF69Gq1atUJGRgbmz5+PHj164NKlS9yPJsCsCgqRlKKjo3Hp0iUcP35c6ihmqVWrVkhMTER+fj62bNmCCRMmIC4uTupYZictLQ0zZszAwYMHYWVlJXUcszZgwADDnwMCAhAcHIwmTZpg06ZNsLa2ljAZAWZ2FU/Dhg2hUCgeGEWdlZUFNzc3iVKZn/v76q/2o5ubG7Kzsyutr6ioQG5ubp3c19OmTcPu3btx5MgReHh4GB53c3ODVqtFXl5epe3/vC8ftq/vr6srlEolWrRogcDAQCxYsADt2rXD0qVLuQ+rKCEhAdnZ2ejYsSMsLCxgYWGBuLg4fPrpp7CwsICrqyv35xNydHREy5Ytce3aNf5emgCzKihKpRKBgYGIjY01PKbX6xEbGwu1Wi1hMvPi7e0NNze3SvtRo9Hg1KlThv2oVquRl5eHhIQEwzaHDx+GXq9HcHBwjWeWihAC06ZNw/bt23H48GF4e3tXWh8YGAhLS8tK+zIlJQWpqamV9uXFixcrFb6DBw/C3t4efn5+NfNBTJBer0dZWRn3YRWFhobi4sWLSExMNCydOnXCmDFjDH/m/nwyhYWFuH79Oho1asTfS1Mg9SjdqtqwYYNQqVRi9erV4vLly+LFF18Ujo6OlUZR0+8j/M+fPy/Onz8vAIhFixaJ8+fPi1u3bgkhfr/M2NHRUXz//ffiwoULYsiQIQ+9zLhDhw7i1KlT4vjx48LHx6fOXWY8depU4eDgII4ePVrpUsTi4mLDNi+99JLw8vIShw8fFmfPnhVqtVqo1WrD+vuXIvbr108kJiaKffv2CWdn5zp1KeJrr70m4uLixI0bN8SFCxfEa6+9JmQymThw4IAQgvvwaf3xKh4huD8f16xZs8TRo0fFjRs3xE8//STCwsJEw4YNRXZ2thCC+1FqZldQhBDis88+E15eXkKpVIrOnTuLkydPSh3J5Bw5ckQAeGCZMGGCEOL3S43ffPNN4erqKlQqlQgNDRUpKSmVXuPu3bti9OjRws7OTtjb24uJEyeKgoICCT6NdB62DwGIVatWGbYpKSkR//znP0X9+vWFjY2NGDZsmMjIyKj0Ojdv3hQDBgwQ1tbWomHDhmLWrFmivLy8hj+NdCZNmiSaNGkilEqlcHZ2FqGhoYZyIgT34dP6c0Hh/nw8I0eOFI0aNRJKpVI0btxYjBw5Uly7ds2wnvtRWjIhhJDm2A0RERHRw5nVGBQiIiKqG1hQiIiIyOSwoBAREZHJYUEhIiIik8OCQkRERCaHBYWIiIhMDgsKERERmRwWFCIiIjI5LChERERkclhQiIiIyOSwoBAREZHJYUEhIiIik/P/AInwdLPX1EAaAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "env.reset()\n",
        "prev_screen = env.render( )\n",
        "plt.imshow(prev_screen)\n",
        "\n",
        "for i in range(40):\n",
        "  # action = env.action_space.sample()  # Random action\n",
        "  action = 2 # Action Hamid modified to practice\n",
        "  obs, reward, terminated, truncated, info = env.step(action)\n",
        "  screen = env.render()\n",
        "\n",
        "  plt.imshow(screen)\n",
        "  ipythondisplay.clear_output(wait=True)\n",
        "  ipythondisplay.display(plt.gcf())\n",
        "\n",
        "  if terminated:\n",
        "    break\n",
        "\n",
        "ipythondisplay.clear_output(wait=True)\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-wa1iuOt4am"
      },
      "source": [
        "But for saving game as **video** he defined a function (it's okay if you don't understand just try to run the code and see the output, then try to modify envs!):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "bhc87xchyeHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a904ef99-a7f2-4269-cb5f-2b27786db433"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/moviepy/config_defaults.py:1: DeprecationWarning: invalid escape sequence '\\P'\n",
            "  \"\"\"\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "from gymnasium.wrappers import RecordEpisodeStatistics, RecordVideo\n",
        "\n",
        "training_period = 250  # record the agent's episode every 250\n",
        "num_training_episodes = 1000  # total number of training episodes\n",
        "\n",
        "env = gym.make(\"MountainCar-v0\", render_mode=\"rgb_array\")\n",
        "env = RecordVideo(env, video_folder=\"MountainCar-v0-agent\", name_prefix=\"training\",\n",
        "                  episode_trigger=lambda x: x % training_period == 0)\n",
        "env = RecordEpisodeStatistics(env)\n",
        "\n",
        "for episode_num in range(num_training_episodes):\n",
        "    obs, info = env.reset()\n",
        "\n",
        "    episode_over = False\n",
        "    while not episode_over:\n",
        "        action = env.action_space.sample()  # replace with actual agent\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "        episode_over = terminated or truncated\n",
        "\n",
        "    logging.info(f\"episode-{episode_num}\", info[\"episode\"])\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZKGl8Ql35k_"
      },
      "source": [
        "The videos are in MountainCar-v0-agent folder of your colab folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfj5rCD1hQ0I"
      },
      "source": [
        "But the car couldn't reach the goal state on top of the right hill. So he tried to implement RL algorithm for learning it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "bjdTspf-hYeU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24680570-b4d7-49fb-9140-f99dec719d68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -200     |\n",
            "| time/              |          |\n",
            "|    fps             | 1047     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 200        |\n",
            "|    ep_rew_mean          | -200       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 746        |\n",
            "|    iterations           | 2          |\n",
            "|    time_elapsed         | 5          |\n",
            "|    total_timesteps      | 4096       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00874098 |\n",
            "|    clip_fraction        | 0.00151    |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.1       |\n",
            "|    explained_variance   | -0.00144   |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 13.8       |\n",
            "|    n_updates            | 10         |\n",
            "|    policy_gradient_loss | -0.00212   |\n",
            "|    value_loss           | 131        |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 200          |\n",
            "|    ep_rew_mean          | -200         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 661          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 9            |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047199614 |\n",
            "|    clip_fraction        | 4.88e-05     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.09        |\n",
            "|    explained_variance   | -0.0321      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 12.9         |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.000751    |\n",
            "|    value_loss           | 89.5         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 200          |\n",
            "|    ep_rew_mean          | -200         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 647          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 12           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019306119 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.1         |\n",
            "|    explained_variance   | -0.0166      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 16.1         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.000414    |\n",
            "|    value_loss           | 84           |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 200          |\n",
            "|    ep_rew_mean          | -200         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 637          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 16           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035407792 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.09        |\n",
            "|    explained_variance   | -0.00995     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 12.6         |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.000482    |\n",
            "|    value_loss           | 68.9         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -200        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 611         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 20          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008626722 |\n",
            "|    clip_fraction        | 0.0354      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.07       |\n",
            "|    explained_variance   | -0.00697    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.58        |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.00373    |\n",
            "|    value_loss           | 54.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -200        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 610         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 23          |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011226503 |\n",
            "|    clip_fraction        | 0.00874     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.07       |\n",
            "|    explained_variance   | -0.00281    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.05        |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.00137    |\n",
            "|    value_loss           | 41.4        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 200          |\n",
            "|    ep_rew_mean          | -200         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 611          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 26           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065861414 |\n",
            "|    clip_fraction        | 0.0022       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.06        |\n",
            "|    explained_variance   | -0.00548     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.86         |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00123     |\n",
            "|    value_loss           | 30.3         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 200          |\n",
            "|    ep_rew_mean          | -200         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 607          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 30           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005192604 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.05        |\n",
            "|    explained_variance   | -0.00223     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.29         |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | 0.000543     |\n",
            "|    value_loss           | 21.1         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 200          |\n",
            "|    ep_rew_mean          | -200         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 599          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 34           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046439907 |\n",
            "|    clip_fraction        | 0.00464      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.06        |\n",
            "|    explained_variance   | -0.00305     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.677        |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | 0.000236     |\n",
            "|    value_loss           | 13.8         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -200        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 600         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 37          |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009531762 |\n",
            "|    clip_fraction        | 0.0125      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.08       |\n",
            "|    explained_variance   | -0.000599   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.575       |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.000845   |\n",
            "|    value_loss           | 8.98        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -200        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 601         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 40          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013026496 |\n",
            "|    clip_fraction        | 0.012       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.06       |\n",
            "|    explained_variance   | -0.00132    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.481       |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.000729   |\n",
            "|    value_loss           | 5.84        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -200        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 593         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 44          |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010373877 |\n",
            "|    clip_fraction        | 0.0186      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.07       |\n",
            "|    explained_variance   | 0.000234    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.116       |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.00228    |\n",
            "|    value_loss           | 3.79        |\n",
            "-----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "\n",
        "# Parallel environments can bet set but Hamid set 1 env\n",
        "vec_env = make_vec_env(\"MountainCar-v0\", n_envs=1)\n",
        "\n",
        "model = PPO(\"MlpPolicy\", vec_env, verbose=1)\n",
        "model.learn(total_timesteps=25000)\n",
        "model.save(\"ppo_MountainCar\")\n",
        "\n",
        "del model # remove to demonstrate saving and loading\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5URzrgeBjA2"
      },
      "source": [
        "**Loading saved model**\n",
        "\n",
        "After training model using PPO and saving it, Hamid started to load the model with the name he saved in cell above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "qHRHFr9-6cgt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22c4e6c7-bc36-45ae-af34-3f00fd0444ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-4.4358733e-01  4.0863737e-04]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-4.4377303e-01 -1.8570265e-04]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.4445517  -0.00077869]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.44591773 -0.001366  ]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.44686106 -0.00094335]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.44837487 -0.00151381]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.4504481  -0.00207322]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.45406556 -0.00361745]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.45920074 -0.00513518]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.46481588 -0.00561516]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.47186965 -0.00705375]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.4783098  -0.00644017]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.4840886  -0.00577879]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.49116302 -0.00707442]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.49748033 -0.00631731]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5049933 -0.007513 ]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5116458  -0.00665246]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5183879  -0.00674209]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5251691  -0.00678117]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5329385 -0.0077694]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5396378  -0.00669936]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.54721695 -0.00757911]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.55561906 -0.00840212]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5627814  -0.00716234]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.56965053 -0.00686915]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5771754  -0.00752486]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.58530015 -0.00812476]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5919648  -0.00666464]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.59912026 -0.00715548]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.6067142 -0.0075939]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.61269116 -0.00597698]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.6190078  -0.00631671]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.6246187  -0.00561087]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.6294835  -0.00486477]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.63456744 -0.00508392]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.63983434 -0.00526694]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.6442471  -0.00441274]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.6467746 -0.0025275]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.6483992  -0.00162456]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.6501094  -0.00171028]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-6.4989352e-01  2.1593773e-04]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-6.4975286e-01  1.4064777e-04]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-6.496885e-01  6.437766e-05]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.6477008   0.00198766]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.64480376  0.00289707]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.64201754  0.00278621]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.63936174  0.00265578]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.6358551   0.00350666]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.6305223   0.00533276]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.6254013  0.005121 ]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.61952865  0.00587271]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.6139463   0.00558229]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.6066947   0.00725163]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5998263   0.00686842]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.59239113  0.00743515]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5854437   0.00694744]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.57703507  0.00840862]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5692274   0.00780768]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.56007856  0.00914883]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5506567   0.00942188]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5410321   0.00962459]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5312768   0.00975528]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.522464    0.00881286]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5146596   0.00780435]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5079223   0.00673731]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5023025   0.00561978]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.49684235  0.00546017]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.49258262  0.00425971]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.4895552   0.00302743]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.48678267  0.00277254]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.48328567  0.00349698]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.48009032  0.00319537]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.47722033  0.00286998]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.47569707  0.00152327]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.47453183  0.00116524]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.47373325  0.00079856]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-4.7330728e-01  4.2596675e-04]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.47425708 -0.00094979]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.47557557 -0.0013185 ]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.47725302 -0.00167743]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.47927693 -0.00202391]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.48063225 -0.00135534]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.48130897 -0.0006767 ]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.48230198 -0.00099302]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.48460394 -0.00230196]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.48619768 -0.00159375]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.48707137 -0.00087367]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-4.8721844e-01 -1.4707915e-04]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.48863783 -0.00141939]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.49031895 -0.00168112]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.49324924 -0.0029303 ]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.49540687 -0.00215761]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.49777564 -0.0023688 ]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.49933794 -0.00156228]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.501082   -0.00174407]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5019948  -0.00091282]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5030696  -0.00107473]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.50529814 -0.00222861]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.506664   -0.00136579]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-5.0715673e-01 -4.9274904e-04]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.50877273 -0.00161601]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5104999  -0.00172717]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5133253  -0.00282539]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.51522774 -0.00190243]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5181929  -0.00296521]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5221987  -0.00400575]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5252149  -0.00301625]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.52921903 -0.00400413]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.533181   -0.00396198]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5360711  -0.00289012]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5388677 -0.0027966]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5405499  -0.00168212]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5431049  -0.00255504]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.54651374 -0.00340883]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5487508  -0.00223711]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5507995  -0.00204864]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5526444  -0.00184486]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5552716 -0.0026273]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.55866176 -0.00339011]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5617894  -0.00312762]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.56463116 -0.00284182]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.568166   -0.00353485]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5723676  -0.00420159]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5752048  -0.00283713]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5766564  -0.00145163]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-5.767118e-01 -5.537471e-05]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5753705   0.00134129]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5746425   0.00072802]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5735331   0.00110935]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-5.730507e-01  4.824594e-04]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-5.7319868e-01 -1.4801054e-04]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.57397604 -0.00077738]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-5.7437706e-01 -4.0098984e-04]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5753987  -0.00102162]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.57703334 -0.00163469]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.578269   -0.00123564]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5800964  -0.00182745]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5815022  -0.00140574]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5834758  -0.00197365]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-5.840028e-01 -5.269829e-04]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.58507925 -0.00107643]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5856972  -0.00061793]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-5.8585209e-01 -1.5488568e-04]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5865428 -0.0006907]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.58776414 -0.00122142]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-5.8750731e-01  2.5685778e-04]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-5.8777410e-01 -2.6675928e-04]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5885625  -0.00078841]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.58986676 -0.00130426]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.59167725 -0.00181052]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5939807  -0.00230347]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.59476024 -0.00077952]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5940101   0.00075014]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-5.9373581e-01  2.7431006e-04]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-5.9393936e-01 -2.0353502e-04]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.59261924  0.00132011]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.59178513  0.00083408]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-5.9144324e-01  3.4191384e-04]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.58959603  0.00184724]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.587257    0.00233899]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5844435   0.00281353]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.58217615  0.00226734]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5794717   0.00270441]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.57735026  0.0021215 ]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5738273   0.00352289]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5699292   0.00389818]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5666846   0.00324454]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.56411785  0.00256679]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5612479   0.00286993]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5570962  0.0041517]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5536937   0.00340251]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5510658   0.00262791]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5482321   0.00283368]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.54621387  0.00201826]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5440261   0.00218775]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5426853   0.00134086]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5412013   0.00148393]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5385854   0.00261588]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5358572   0.00272825]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.532037    0.00382016]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5281536   0.00388344]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.523236   0.0049176]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5193211   0.00391488]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5144383  0.0048828]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5106242   0.00381411]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.50690734  0.00371682]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5033157   0.00359169]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.49987602  0.00343966]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.49661413  0.00326189]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.4945544   0.00205972]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.49371225  0.00084217]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-4.9409392e-01 -3.8168224e-04]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-4.9369660e-01  3.9732025e-04]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-4.9352324e-01  1.7335468e-04]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.49457517 -0.00105191]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.49684447 -0.00226931]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.49931422 -0.00246975]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.50196594 -0.00265172]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.5047798  -0.00281386]] [-1.] [False] [{'TimeLimit.truncated': False}]\n",
            "[[-0.4817115  0.       ]] [-1.] [ True] [{'episode': {'r': -200.0, 'l': 200, 't': 47.086431}, 'TimeLimit.truncated': True, 'terminal_observation': array([-0.5077347 , -0.00295492], dtype=float32)}]\n"
          ]
        }
      ],
      "source": [
        "model = PPO.load(\"ppo_MountainCar\")\n",
        "\n",
        "obs = vec_env.reset()\n",
        "while True:\n",
        "    action, _states = model.predict(obs)\n",
        "    obs, rewards, dones, info = vec_env.step(action)\n",
        "    print(obs, rewards, dones, info)\n",
        "    if dones[0]:\n",
        "      break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-Jjj_0Q9hX_"
      },
      "source": [
        "# **Task 1: Solving Predefined Environments (45 points)**\n",
        "1.1. Choose two environments from the list which are implemented by  other developers and communities and train RL agents using stable-baselines3. Don't forget to check workshop notebook.\n",
        "\n",
        "**Environments:**\n",
        "- [CartPole](https://gymnasium.farama.org/environments/classic_control/cart_pole/)\n",
        "- [FrozenLake](https://gymnasium.farama.org/environments/toy_text/frozen_lake/)\n",
        "- [Taxi](https://gymnasium.farama.org/environments/toy_text/taxi/)\n",
        "- Flappy Bird (Custom env which you can google it)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryQkECp8hr9v"
      },
      "source": [
        "📊 1.2. Algorithm Comparison:\n",
        "\n",
        "\n",
        " Compare RL algorithms and results (at least two algorithms e.g., PPO, DQN) based on:\n",
        "- Total reward over time\n",
        "- Hyperparameters (check the docs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kis3E_faEs6H"
      },
      "source": [
        "Env1 implementation. [ place for your code ]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium import Wrapper, RewardWrapper\n",
        "from stable_baselines3 import PPO, DQN\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import numpy as np\n",
        "from itertools import product\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "class EpisodeTracker(Wrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        self.episode_rewards = []\n",
        "        self.episode_lengths = []\n",
        "        self.current_episode_reward = 0\n",
        "        self.current_episode_length = 0\n",
        "\n",
        "    def step(self, action):\n",
        "        obs, reward, terminated, truncated, info = super().step(action)\n",
        "        self.current_episode_reward += reward\n",
        "        self.current_episode_length += 1\n",
        "        if terminated or truncated:\n",
        "            self.episode_rewards.append(self.current_episode_reward)\n",
        "            self.episode_lengths.append(self.current_episode_length)\n",
        "            self.current_episode_reward = 0\n",
        "            self.current_episode_length = 0\n",
        "        return obs, reward, terminated, truncated, info\n",
        "\n",
        "    def get_episode_rewards(self):\n",
        "        return self.episode_rewards\n",
        "\n",
        "    def get_episode_lengths(self):\n",
        "        return self.episode_lengths\n",
        "\n",
        "\n",
        "class MetricsCollectorCallback(BaseCallback):\n",
        "    def __init__(self, verbose=0):\n",
        "        super().__init__(verbose)\n",
        "        self.episode_rewards = []\n",
        "        self.episode_lengths = []\n",
        "        self.timesteps = []\n",
        "        self.last_episode_count = 0\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        vec_env = self.model.get_env()\n",
        "        env = vec_env.envs[0].env\n",
        "        if isinstance(env, EpisodeTracker):\n",
        "            current_episode_count = len(env.get_episode_rewards())\n",
        "            if current_episode_count > self.last_episode_count:\n",
        "                new_episodes = current_episode_count - self.last_episode_count\n",
        "                ep_rewards = env.get_episode_rewards()[self.last_episode_count:]\n",
        "                ep_lengths = env.get_episode_lengths()[self.last_episode_count:]\n",
        "\n",
        "                self.episode_rewards.append(np.mean(ep_rewards))\n",
        "                self.episode_lengths.append(np.mean(ep_lengths))\n",
        "                self.timesteps.append(self.num_timesteps)\n",
        "                self.last_episode_count = current_episode_count\n",
        "        return True\n",
        "\n",
        "def train_hyperparams(model_class, param_grid, use_custom_reward=False, total_timesteps=20000):\n",
        "    results = []\n",
        "    grid = ParameterGrid(param_grid)\n",
        "\n",
        "    for idx, params in enumerate(grid):\n",
        "        print(f\"\\nTraining combination {idx+1}/{len(grid)}\")\n",
        "        print(params)\n",
        "\n",
        "        env = create_env(use_custom_reward)\n",
        "        callback = MetricsCollectorCallback()\n",
        "\n",
        "        model = model_class('MlpPolicy', env, verbose=0, **params)\n",
        "        model.learn(total_timesteps=total_timesteps, callback=callback)\n",
        "\n",
        "        results.append({\n",
        "            'params': params,\n",
        "            'rewards': callback.episode_rewards,\n",
        "            'lengths': callback.episode_lengths,\n",
        "            'timesteps': callback.timesteps\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# def plot_hyperparam_results(results, base_title):\n",
        "#     plt.figure(figsize=(12, 6))\n",
        "#     cmap = plt.get_cmap('tab20')\n",
        "\n",
        "#     for i, result in enumerate(results):\n",
        "#         title = base_title + \" \".join([f\"{k}: {v}\" for k,v in result['params'].items()])\n",
        "#         plt.plot(result['timesteps'], result['rewards'], color=cmap(i/len(results)), alpha=0.7)\n",
        "#         plt.xlabel('Timesteps')\n",
        "#         plt.ylabel('Mean Episode Reward')\n",
        "#         plt.title(title)\n",
        "#         plt.tight_layout()\n",
        "#         plt.show()\n",
        "#         title = base_title + \" \".join([f\"{k}: {v}\" for k,v in result['params'].items()])\n",
        "#         plt.plot(result['timesteps'], result['lengths'], color=cmap(i/len(results)), alpha=0.7)\n",
        "#         plt.xlabel('Timesteps')\n",
        "#         plt.ylabel('Mean Episode Length')\n",
        "#         plt.title(title)\n",
        "#         plt.tight_layout()\n",
        "#         plt.show()\n",
        "\n",
        "def plot_hyperparam_results(results, base_title):\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    cmap = plt.get_cmap('tab20')\n",
        "\n",
        "    ax1 = plt.subplot(2, 1, 1)\n",
        "    ax2 = plt.subplot(2, 1, 2)\n",
        "\n",
        "    handles = []\n",
        "    labels = []\n",
        "\n",
        "    for i, result in enumerate(results):\n",
        "        color = cmap(i/len(results))\n",
        "        label = \", \".join([f\"{k}:{v}\" for k, v in result['params'].items()])\n",
        "\n",
        "        line1, = ax1.plot(result['timesteps'], result['rewards'],\n",
        "                         color=color, alpha=0.7)\n",
        "\n",
        "        line2, = ax2.plot(result['timesteps'], result['lengths'],\n",
        "                         color=color, alpha=0.7)\n",
        "\n",
        "        handles.append(line1)\n",
        "        labels.append(label)\n",
        "\n",
        "    ax1.set_xlabel('Timesteps')\n",
        "    ax1.set_ylabel('Mean Episode Reward')\n",
        "    ax1.set_title(f'{base_title} - Reward')\n",
        "    ax1.grid(True)\n",
        "\n",
        "    ax2.set_xlabel('Timesteps')\n",
        "    ax2.set_ylabel('Mean Episode Length')\n",
        "    ax2.set_title(f'{base_title} - Length')\n",
        "    ax2.grid(True)\n",
        "\n",
        "    plt.figlegend(handles, labels, loc='upper center', ncol=2, bbox_to_anchor=(0.5, 1.05))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def get_best_run(results):\n",
        "    best_max_reward = -np.inf\n",
        "    best_run = None\n",
        "    for result in results:\n",
        "        if not result['rewards']:\n",
        "            continue\n",
        "        max_reward = max(result['rewards'])\n",
        "        if max_reward > best_max_reward:\n",
        "            best_max_reward = max_reward\n",
        "            best_run = result\n",
        "    return best_run\n",
        "\n",
        "def compare_best_runs(results_sets, labels):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for results, label in zip(results_sets, labels):\n",
        "        best_run = max(results, key=lambda x: np.max(x['rewards']))\n",
        "        plt.plot(best_run['timesteps'], best_run['rewards'], label=label)\n",
        "    plt.xlabel('Timesteps')\n",
        "    plt.ylabel('Mean Episode Reward')\n",
        "    plt.title('Best Run Comparison')\n",
        "    plt.axhline(y=8, color='r', linestyle='--', label='Solved Threshold')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def analyze_convergence(results, window=100, threshold=8):\n",
        "    for result in results:\n",
        "        rewards = result['rewards']\n",
        "        if len(rewards) < window:\n",
        "            continue\n",
        "        rolling_avg = np.convolve(rewards, np.ones(window)/window, mode='valid')\n",
        "        converged = np.any(rolling_avg >= threshold)\n",
        "        print(f\"Params: {result['params']}\")\n",
        "        print(f\"Max reward: {np.max(rewards):.2f}\")\n",
        "        print(f\"Converged: {'Yes' if converged else 'No'}\")\n",
        "        print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "xMW5ovD5zG_5"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_env(use_custom_reward=False):\n",
        "    env = gym.make('CartPole-v1')\n",
        "    if use_custom_reward:\n",
        "        env = CustomRewardWrapper(env)\n",
        "    env = EpisodeTracker(env)\n",
        "    return env\n",
        "\n",
        "class CustomRewardWrapper(RewardWrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "\n",
        "    def reward(self, reward):\n",
        "        obs = self.env.unwrapped.state\n",
        "        if obs is None:\n",
        "            obs = self.env.unwrapped._get_obs()\n",
        "\n",
        "        pole_angle = obs[2]\n",
        "        return reward - 0.1 * abs(pole_angle)\n",
        "\n",
        "ppo_params = {\n",
        "    'learning_rate': [3e-4, 1e-3],\n",
        "    'n_steps': [2048, 1024, 512],\n",
        "    'gamma': [0.95, 0.99],\n",
        "    'clip_range': [0.1, 0.3]\n",
        "}\n",
        "\n",
        "dqn_params = {\n",
        "    'learning_rate': [3e-4, 1e-3],\n",
        "    'buffer_size': [10000, 50000],\n",
        "    'exploration_final_eps': [0.01, 0.1],\n",
        "    'target_update_interval': [100, 500]\n",
        "}\n",
        "\n",
        "# ppo_params = {\n",
        "#     'learning_rate': [3e-4],\n",
        "#     'n_steps': [2048],\n",
        "#     'gamma': [0.95],\n",
        "#     'clip_range': [0.1]\n",
        "# }\n",
        "\n",
        "# dqn_params = {\n",
        "#     'learning_rate': [3e-4],\n",
        "#     'buffer_size': [10000],\n",
        "#     'exploration_final_eps': [0.01],\n",
        "#     'target_update_interval': [100]\n",
        "# }\n",
        "\n",
        "ppo_results = train_hyperparams(PPO, ppo_params)\n",
        "dqn_results = train_hyperparams(DQN, dqn_params)\n",
        "\n",
        "ppo_results_mod = train_hyperparams(PPO, ppo_params, use_custom_reward=True)\n",
        "dqn_results_mod = train_hyperparams(DQN, dqn_params, use_custom_reward=True)\n",
        "\n",
        "plot_hyperparam_results(ppo_results, 'PPO ')\n",
        "plot_hyperparam_results(ppo_results_mod, 'PPO Modified ')\n",
        "plot_hyperparam_results(dqn_results, 'DQN ')\n",
        "plot_hyperparam_results(dqn_results_mod, 'DQN Modified ')\n",
        "\n",
        "print(\"\\nPPO Standard Convergence Analysis:\")\n",
        "analyze_convergence(ppo_results)\n",
        "print(\"\\nPPO Modified Convergence Analysis:\")\n",
        "analyze_convergence(ppo_results_mod)\n",
        "print(\"\\nDQN Standard Convergence Analysis:\")\n",
        "analyze_convergence(dqn_results)\n",
        "print(\"\\nDQN Modified Convergence Analysis:\")\n",
        "analyze_convergence(dqn_results_mod)\n",
        "\n",
        "compare_best_runs(\n",
        "    [ppo_results, ppo_results_mod, dqn_results, dqn_results_mod],\n",
        "    ['PPO Standard', 'PPO Modified', 'DQN Standard', 'DQN Modified']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBDMB5xWG6uz",
        "outputId": "9eff8326-6e12-497b-e12c-eff2eda7d5de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training combination 1/24\n",
            "{'clip_range': 0.1, 'gamma': 0.95, 'learning_rate': 0.0003, 'n_steps': 2048}\n",
            "\n",
            "Training combination 2/24\n",
            "{'clip_range': 0.1, 'gamma': 0.95, 'learning_rate': 0.0003, 'n_steps': 1024}\n",
            "\n",
            "Training combination 3/24\n",
            "{'clip_range': 0.1, 'gamma': 0.95, 'learning_rate': 0.0003, 'n_steps': 512}\n",
            "\n",
            "Training combination 4/24\n",
            "{'clip_range': 0.1, 'gamma': 0.95, 'learning_rate': 0.001, 'n_steps': 2048}\n",
            "\n",
            "Training combination 5/24\n",
            "{'clip_range': 0.1, 'gamma': 0.95, 'learning_rate': 0.001, 'n_steps': 1024}\n",
            "\n",
            "Training combination 6/24\n",
            "{'clip_range': 0.1, 'gamma': 0.95, 'learning_rate': 0.001, 'n_steps': 512}\n",
            "\n",
            "Training combination 7/24\n",
            "{'clip_range': 0.1, 'gamma': 0.99, 'learning_rate': 0.0003, 'n_steps': 2048}\n",
            "\n",
            "Training combination 8/24\n",
            "{'clip_range': 0.1, 'gamma': 0.99, 'learning_rate': 0.0003, 'n_steps': 1024}\n",
            "\n",
            "Training combination 9/24\n",
            "{'clip_range': 0.1, 'gamma': 0.99, 'learning_rate': 0.0003, 'n_steps': 512}\n",
            "\n",
            "Training combination 10/24\n",
            "{'clip_range': 0.1, 'gamma': 0.99, 'learning_rate': 0.001, 'n_steps': 2048}\n",
            "\n",
            "Training combination 11/24\n",
            "{'clip_range': 0.1, 'gamma': 0.99, 'learning_rate': 0.001, 'n_steps': 1024}\n",
            "\n",
            "Training combination 12/24\n",
            "{'clip_range': 0.1, 'gamma': 0.99, 'learning_rate': 0.001, 'n_steps': 512}\n",
            "\n",
            "Training combination 13/24\n",
            "{'clip_range': 0.3, 'gamma': 0.95, 'learning_rate': 0.0003, 'n_steps': 2048}\n",
            "\n",
            "Training combination 14/24\n",
            "{'clip_range': 0.3, 'gamma': 0.95, 'learning_rate': 0.0003, 'n_steps': 1024}\n",
            "\n",
            "Training combination 15/24\n",
            "{'clip_range': 0.3, 'gamma': 0.95, 'learning_rate': 0.0003, 'n_steps': 512}\n",
            "\n",
            "Training combination 16/24\n",
            "{'clip_range': 0.3, 'gamma': 0.95, 'learning_rate': 0.001, 'n_steps': 2048}\n",
            "\n",
            "Training combination 17/24\n",
            "{'clip_range': 0.3, 'gamma': 0.95, 'learning_rate': 0.001, 'n_steps': 1024}\n",
            "\n",
            "Training combination 18/24\n",
            "{'clip_range': 0.3, 'gamma': 0.95, 'learning_rate': 0.001, 'n_steps': 512}\n",
            "\n",
            "Training combination 19/24\n",
            "{'clip_range': 0.3, 'gamma': 0.99, 'learning_rate': 0.0003, 'n_steps': 2048}\n",
            "\n",
            "Training combination 20/24\n",
            "{'clip_range': 0.3, 'gamma': 0.99, 'learning_rate': 0.0003, 'n_steps': 1024}\n",
            "\n",
            "Training combination 21/24\n",
            "{'clip_range': 0.3, 'gamma': 0.99, 'learning_rate': 0.0003, 'n_steps': 512}\n",
            "\n",
            "Training combination 22/24\n",
            "{'clip_range': 0.3, 'gamma': 0.99, 'learning_rate': 0.001, 'n_steps': 2048}\n",
            "\n",
            "Training combination 23/24\n",
            "{'clip_range': 0.3, 'gamma': 0.99, 'learning_rate': 0.001, 'n_steps': 1024}\n",
            "\n",
            "Training combination 24/24\n",
            "{'clip_range': 0.3, 'gamma': 0.99, 'learning_rate': 0.001, 'n_steps': 512}\n",
            "\n",
            "Training combination 1/16\n",
            "{'buffer_size': 10000, 'exploration_final_eps': 0.01, 'learning_rate': 0.0003, 'target_update_interval': 100}\n",
            "\n",
            "Training combination 2/16\n",
            "{'buffer_size': 10000, 'exploration_final_eps': 0.01, 'learning_rate': 0.0003, 'target_update_interval': 500}\n",
            "\n",
            "Training combination 3/16\n",
            "{'buffer_size': 10000, 'exploration_final_eps': 0.01, 'learning_rate': 0.001, 'target_update_interval': 100}\n",
            "\n",
            "Training combination 4/16\n",
            "{'buffer_size': 10000, 'exploration_final_eps': 0.01, 'learning_rate': 0.001, 'target_update_interval': 500}\n",
            "\n",
            "Training combination 5/16\n",
            "{'buffer_size': 10000, 'exploration_final_eps': 0.1, 'learning_rate': 0.0003, 'target_update_interval': 100}\n",
            "\n",
            "Training combination 6/16\n",
            "{'buffer_size': 10000, 'exploration_final_eps': 0.1, 'learning_rate': 0.0003, 'target_update_interval': 500}\n",
            "\n",
            "Training combination 7/16\n",
            "{'buffer_size': 10000, 'exploration_final_eps': 0.1, 'learning_rate': 0.001, 'target_update_interval': 100}\n",
            "\n",
            "Training combination 8/16\n",
            "{'buffer_size': 10000, 'exploration_final_eps': 0.1, 'learning_rate': 0.001, 'target_update_interval': 500}\n",
            "\n",
            "Training combination 9/16\n",
            "{'buffer_size': 50000, 'exploration_final_eps': 0.01, 'learning_rate': 0.0003, 'target_update_interval': 100}\n",
            "\n",
            "Training combination 10/16\n",
            "{'buffer_size': 50000, 'exploration_final_eps': 0.01, 'learning_rate': 0.0003, 'target_update_interval': 500}\n",
            "\n",
            "Training combination 11/16\n",
            "{'buffer_size': 50000, 'exploration_final_eps': 0.01, 'learning_rate': 0.001, 'target_update_interval': 100}\n",
            "\n",
            "Training combination 12/16\n",
            "{'buffer_size': 50000, 'exploration_final_eps': 0.01, 'learning_rate': 0.001, 'target_update_interval': 500}\n",
            "\n",
            "Training combination 13/16\n",
            "{'buffer_size': 50000, 'exploration_final_eps': 0.1, 'learning_rate': 0.0003, 'target_update_interval': 100}\n",
            "\n",
            "Training combination 14/16\n",
            "{'buffer_size': 50000, 'exploration_final_eps': 0.1, 'learning_rate': 0.0003, 'target_update_interval': 500}\n",
            "\n",
            "Training combination 15/16\n",
            "{'buffer_size': 50000, 'exploration_final_eps': 0.1, 'learning_rate': 0.001, 'target_update_interval': 100}\n",
            "\n",
            "Training combination 16/16\n",
            "{'buffer_size': 50000, 'exploration_final_eps': 0.1, 'learning_rate': 0.001, 'target_update_interval': 500}\n",
            "\n",
            "Training combination 1/24\n",
            "{'clip_range': 0.1, 'gamma': 0.95, 'learning_rate': 0.0003, 'n_steps': 2048}\n",
            "\n",
            "Training combination 2/24\n",
            "{'clip_range': 0.1, 'gamma': 0.95, 'learning_rate': 0.0003, 'n_steps': 1024}\n",
            "\n",
            "Training combination 3/24\n",
            "{'clip_range': 0.1, 'gamma': 0.95, 'learning_rate': 0.0003, 'n_steps': 512}\n",
            "\n",
            "Training combination 4/24\n",
            "{'clip_range': 0.1, 'gamma': 0.95, 'learning_rate': 0.001, 'n_steps': 2048}\n",
            "\n",
            "Training combination 5/24\n",
            "{'clip_range': 0.1, 'gamma': 0.95, 'learning_rate': 0.001, 'n_steps': 1024}\n",
            "\n",
            "Training combination 6/24\n",
            "{'clip_range': 0.1, 'gamma': 0.95, 'learning_rate': 0.001, 'n_steps': 512}\n",
            "\n",
            "Training combination 7/24\n",
            "{'clip_range': 0.1, 'gamma': 0.99, 'learning_rate': 0.0003, 'n_steps': 2048}\n",
            "\n",
            "Training combination 8/24\n",
            "{'clip_range': 0.1, 'gamma': 0.99, 'learning_rate': 0.0003, 'n_steps': 1024}\n",
            "\n",
            "Training combination 9/24\n",
            "{'clip_range': 0.1, 'gamma': 0.99, 'learning_rate': 0.0003, 'n_steps': 512}\n",
            "\n",
            "Training combination 10/24\n",
            "{'clip_range': 0.1, 'gamma': 0.99, 'learning_rate': 0.001, 'n_steps': 2048}\n",
            "\n",
            "Training combination 11/24\n",
            "{'clip_range': 0.1, 'gamma': 0.99, 'learning_rate': 0.001, 'n_steps': 1024}\n",
            "\n",
            "Training combination 12/24\n",
            "{'clip_range': 0.1, 'gamma': 0.99, 'learning_rate': 0.001, 'n_steps': 512}\n",
            "\n",
            "Training combination 13/24\n",
            "{'clip_range': 0.3, 'gamma': 0.95, 'learning_rate': 0.0003, 'n_steps': 2048}\n",
            "\n",
            "Training combination 14/24\n",
            "{'clip_range': 0.3, 'gamma': 0.95, 'learning_rate': 0.0003, 'n_steps': 1024}\n",
            "\n",
            "Training combination 15/24\n",
            "{'clip_range': 0.3, 'gamma': 0.95, 'learning_rate': 0.0003, 'n_steps': 512}\n",
            "\n",
            "Training combination 16/24\n",
            "{'clip_range': 0.3, 'gamma': 0.95, 'learning_rate': 0.001, 'n_steps': 2048}\n",
            "\n",
            "Training combination 17/24\n",
            "{'clip_range': 0.3, 'gamma': 0.95, 'learning_rate': 0.001, 'n_steps': 1024}\n",
            "\n",
            "Training combination 18/24\n",
            "{'clip_range': 0.3, 'gamma': 0.95, 'learning_rate': 0.001, 'n_steps': 512}\n",
            "\n",
            "Training combination 19/24\n",
            "{'clip_range': 0.3, 'gamma': 0.99, 'learning_rate': 0.0003, 'n_steps': 2048}\n",
            "\n",
            "Training combination 20/24\n",
            "{'clip_range': 0.3, 'gamma': 0.99, 'learning_rate': 0.0003, 'n_steps': 1024}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ppo_standard_best = get_best_run(ppo_results)\n",
        "ppo_mod_best = get_best_run(ppo_results_mod)\n",
        "dqn_standard_best = get_best_run(dqn_results)\n",
        "dqn_mod_best = get_best_run(dqn_results_mod)\n",
        "\n",
        "best_ppo = max([ppo_standard_best, ppo_mod_best], key=lambda x: max(x['rewards']) if ppo_standard_best and ppo_mod_best else None)\n",
        "best_dqn = max([dqn_standard_best, dqn_mod_best], key=lambda x: max(x['rewards']) if dqn_standard_best and dqn_mod_best else None)\n",
        "\n",
        "print(\"PPO Best (Standard) Max Reward:\", max(ppo_standard_best['rewards']) if ppo_standard_best else \"N/A\")\n",
        "print(\"PPO Best (Modified) Max Reward:\", max(ppo_mod_best['rewards']) if ppo_mod_best else \"N/A\")\n",
        "print(\"DQN Best (Standard) Max Reward:\", max(dqn_standard_best['rewards']) if dqn_standard_best else \"N/A\")\n",
        "print(\"DQN Best (Modified) Max Reward:\", max(dqn_mod_best['rewards']) if dqn_mod_best else \"N/A\")\n",
        "\n",
        "if best_ppo and best_dqn:\n",
        "    print(\"\\nOverall Best PPO Reward:\", max(best_ppo['rewards']))\n",
        "    print(\"Overall Best DQN Reward:\", max(best_dqn['rewards']))"
      ],
      "metadata": {
        "id": "sw5aakzCAeDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ5mY77EE9o3"
      },
      "source": [
        "Env2 implementation. [ place for your code ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcEAbUJ-ErwT"
      },
      "outputs": [],
      "source": [
        "def create_env(use_custom_reward=False):\n",
        "    env = gym.make('Taxi-v3')\n",
        "    if use_custom_reward:\n",
        "        env = CustomRewardWrapper(env)\n",
        "    env = EpisodeTracker(env)\n",
        "    return env\n",
        "\n",
        "class CustomRewardWrapper(RewardWrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        self.last_obs = None\n",
        "\n",
        "    def step(self, action):\n",
        "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
        "        self.last_obs = obs\n",
        "        modified_reward = self.reward(reward)\n",
        "        return obs, modified_reward, terminated, truncated, info\n",
        "\n",
        "    def reward(self, reward):\n",
        "        if self.last_obs is not None:\n",
        "            taxi_row, taxi_col, pass_loc, dest_idx = self.env.unwrapped.decode(self.last_obs)\n",
        "\n",
        "            distance_penalty = 0.0\n",
        "            bonus = 0.0\n",
        "\n",
        "            if pass_loc == 4:\n",
        "                dest_row, dest_col = self.env.unwrapped.locs[dest_idx]\n",
        "                distance = abs(taxi_row - dest_row) + abs(taxi_col - dest_col)\n",
        "                distance_penalty = -0.1 * distance\n",
        "\n",
        "            if reward == 20:\n",
        "                bonus = 2.0\n",
        "\n",
        "            return reward + distance_penalty + bonus\n",
        "        return reward\n",
        "\n",
        "ppo_params = {\n",
        "    'learning_rate': [3e-4, 1e-3],\n",
        "    'n_steps': [2048, 1024, 512],\n",
        "    'gamma': [0.95, 0.99],\n",
        "    'clip_range': [0.1, 0.3]\n",
        "}\n",
        "\n",
        "dqn_params = {\n",
        "    'learning_rate': [3e-4, 1e-3],\n",
        "    'buffer_size': [10000, 50000],\n",
        "    'exploration_final_eps': [0.01, 0.1],\n",
        "    'target_update_interval': [100, 500]\n",
        "}\n",
        "\n",
        "# ppo_params = {\n",
        "#     'learning_rate': [3e-4],\n",
        "#     'n_steps': [2048],\n",
        "#     'gamma': [0.95],\n",
        "#     'clip_range': [0.1]\n",
        "# }\n",
        "\n",
        "# dqn_params = {\n",
        "#     'learning_rate': [3e-4],\n",
        "#     'buffer_size': [10000],\n",
        "#     'exploration_final_eps': [0.01],\n",
        "#     'target_update_interval': [100]\n",
        "# }\n",
        "\n",
        "ppo_results = train_hyperparams(PPO, ppo_params)\n",
        "dqn_results = train_hyperparams(DQN, dqn_params)\n",
        "\n",
        "ppo_results_mod = train_hyperparams(PPO, ppo_params, use_custom_reward=True)\n",
        "dqn_results_mod = train_hyperparams(DQN, dqn_params, use_custom_reward=True)\n",
        "\n",
        "plot_hyperparam_results(ppo_results, 'PPO ')\n",
        "plot_hyperparam_results(ppo_results_mod, 'PPO Modified ')\n",
        "plot_hyperparam_results(dqn_results, 'DQN ')\n",
        "plot_hyperparam_results(dqn_results_mod, 'DQN Modified ')\n",
        "\n",
        "print(\"\\nPPO Standard Convergence Analysis:\")\n",
        "analyze_convergence(ppo_results)\n",
        "print(\"\\nPPO Modified Convergence Analysis:\")\n",
        "analyze_convergence(ppo_results_mod)\n",
        "print(\"\\nDQN Standard Convergence Analysis:\")\n",
        "analyze_convergence(dqn_results)\n",
        "print(\"\\nDQN Modified Convergence Analysis:\")\n",
        "analyze_convergence(dqn_results_mod)\n",
        "\n",
        "\n",
        "compare_best_runs(\n",
        "    [ppo_results, ppo_results_mod, dqn_results, dqn_results_mod],\n",
        "    ['PPO Standard', 'PPO Modified', 'DQN Standard', 'DQN Modified']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ppo_standard_best = get_best_run(ppo_results)\n",
        "ppo_mod_best = get_best_run(ppo_results_mod)\n",
        "dqn_standard_best = get_best_run(dqn_results)\n",
        "dqn_mod_best = get_best_run(dqn_results_mod)\n",
        "\n",
        "best_ppo = max([ppo_standard_best, ppo_mod_best], key=lambda x: max(x['rewards']) if ppo_standard_best and ppo_mod_best else None)\n",
        "best_dqn = max([dqn_standard_best, dqn_mod_best], key=lambda x: max(x['rewards']) if dqn_standard_best and dqn_mod_best else None)\n",
        "\n",
        "print(\"PPO Best (Standard) Max Reward:\", max(ppo_standard_best['rewards']) if ppo_standard_best else \"N/A\")\n",
        "print(\"PPO Best (Modified) Max Reward:\", max(ppo_mod_best['rewards']) if ppo_mod_best else \"N/A\")\n",
        "print(\"DQN Best (Standard) Max Reward:\", max(dqn_standard_best['rewards']) if dqn_standard_best else \"N/A\")\n",
        "print(\"DQN Best (Modified) Max Reward:\", max(dqn_mod_best['rewards']) if dqn_mod_best else \"N/A\")\n",
        "\n",
        "if best_ppo and best_dqn:\n",
        "    print(\"\\nOverall Best PPO Reward:\", max(best_ppo['rewards']))\n",
        "    print(\"Overall Best DQN Reward:\", max(best_dqn['rewards']))"
      ],
      "metadata": {
        "id": "_xeCnjJaIe2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9M73XwdSISN"
      },
      "source": [
        "Write a wrapper for changing reward function and plot the changes. (Bonus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXJhDfvXR6IO"
      },
      "outputs": [],
      "source": [
        "# Bonus TODO's: Your wrapper for reward function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py94B6gw9hYA"
      },
      "source": [
        "# **Task 2: Creating Custom Environment (45 points)**\n",
        "In this question, you are required to model **a custom 4*4 gridworld problem** as Markov Decision Processes (MDPs). You must define the following components:\n",
        "\n",
        "<img src=\"data:image/png;base64,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\" width=\"400\"/>\n",
        "\n",
        "- **State Space ($ S $)**: The set of all possible states the agent can be in.\n",
        "- **Action Space ($ A $)**: The set of all possible actions the agent can take.\n",
        "- **Reward Function ($ R $)**: The reward the agent receives for taking an action in a given state.\n",
        "- **Transition Probability ($ P $)**: The probability of transitioning to a new state given the current state and action. If the environment is deterministic, this can be omitted.\n",
        "\n",
        "After defining the MDP components, implement problem using the **Gymnasium standard API**. Then, test the environments using various reinforcement learning algorithms (e.g., Q-Learning, DQN, PPO) and evaluate their performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgkvovqQiB8c"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "from typing import Any, SupportsFloat, Tuple, Dict\n",
        "\n",
        "class YourAwesomeEnvironment(gym.Env):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "        self.observation_space = spaces.Box(low=np.array([0, 0]), high=np.array([3, 3]), dtype=int)\n",
        "        self.grid_size = 4\n",
        "        self.start_pos = (0, 0)\n",
        "        self.goal_pos = (3, 3)\n",
        "        self.blocked_positions = [(1, 1), (2, 2)]\n",
        "        self.state = self.start_pos\n",
        "        self.max_steps = 200\n",
        "        self.current_steps = 0\n",
        "        self.prev_dist = None\n",
        "\n",
        "    def step(\n",
        "        self, action: Any\n",
        "    ) -> tuple[Any, SupportsFloat, bool, bool, dict[str, Any]]:\n",
        "        x, y = self.state\n",
        "\n",
        "        if action == 0:\n",
        "            x = max(x - 1, 0)\n",
        "        elif action == 1:\n",
        "            x = min(x + 1, self.grid_size - 1)\n",
        "        elif action == 2:\n",
        "            y = max(y - 1, 0)\n",
        "        elif action == 3:\n",
        "            y = min(y + 1, self.grid_size - 1)\n",
        "\n",
        "        if (x, y) in self.blocked_positions:\n",
        "            x, y = self.state\n",
        "\n",
        "        self.state = (x, y)\n",
        "        terminated = (x, y) == self.goal_pos\n",
        "        self.current_steps += 1  # Track steps\n",
        "        truncated = self.current_steps >= self.max_steps  # Auto-truncate\n",
        "\n",
        "        goal_dist = abs(x - self.goal_pos[0]) + abs(y - self.goal_pos[1])\n",
        "\n",
        "        reward = -0.1  # Penalize long paths\n",
        "        if self.prev_dist is not None:\n",
        "            progress_bonus = 0.5 * (self.prev_dist - goal_dist)\n",
        "            reward += progress_bonus\n",
        "\n",
        "        if terminated:\n",
        "            reward += 10.0  # Large success bonus\n",
        "        self.prev_dist = goal_dist\n",
        "\n",
        "        info = {}\n",
        "\n",
        "        return np.array(self.state, dtype=int), reward, terminated, truncated, info\n",
        "\n",
        "    def reset(\n",
        "        self, *, seed: int | None = None, options: dict[str, Any] | None = None\n",
        "    ) -> tuple[Any, dict[str, Any]]:\n",
        "\n",
        "        self.state = self.start_pos\n",
        "        self.current_steps = 0  # Reset counter\n",
        "\n",
        "\n",
        "        return np.array(self.state, dtype=int), {}\n",
        "\n",
        "    def render(self):\n",
        "        grid = np.zeros((self.grid_size, self.grid_size), dtype=str)\n",
        "        grid[self.start_pos] = \"S\"\n",
        "        grid[self.goal_pos] = \"G\"\n",
        "        for pos in self.blocked_positions:\n",
        "            grid[pos] = \"X\"\n",
        "        grid[self.state] = \"P\"\n",
        "\n",
        "        print(\"Grid World:\")\n",
        "        print(grid)\n",
        "        print()\n",
        "\n",
        "    def close(self):\n",
        "        print(\"Environment closed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FAu2qEd9hYA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3 import PPO, DQN\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "\n",
        "TOTAL_TIMESTEPS = 30000\n",
        "EVAL_EPISODES = 100\n",
        "\n",
        "class TrainingMetricsCallback(BaseCallback):\n",
        "    def __init__(self, verbose=0):\n",
        "        super().__init__(verbose)\n",
        "        self.episode_rewards = []\n",
        "        self.episode_lengths = []\n",
        "        self.current_ep_reward = 0\n",
        "        self.current_ep_length = 0\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        reward = self.locals[\"rewards\"][0]\n",
        "        done = self.locals[\"dones\"][0]\n",
        "\n",
        "        self.current_ep_reward += reward\n",
        "        self.current_ep_length += 1\n",
        "\n",
        "        if done:\n",
        "            self.episode_rewards.append(self.current_ep_reward)\n",
        "            self.episode_lengths.append(self.current_ep_length)\n",
        "            self.current_ep_reward = 0\n",
        "            self.current_ep_length = 0\n",
        "\n",
        "        return True\n",
        "\n",
        "def train_model(model_class, env, timesteps=TOTAL_TIMESTEPS):\n",
        "    callback = TrainingMetricsCallback()\n",
        "    model = model_class(\"MlpPolicy\", env, verbose=0)\n",
        "    model.learn(total_timesteps=timesteps, callback=callback)\n",
        "    return model, callback.episode_rewards, callback.episode_lengths\n",
        "\n",
        "# def evaluate_model(model, env, n_episodes=EVAL_EPISODES):\n",
        "#     success_count = 0\n",
        "#     episode_lengths = []\n",
        "\n",
        "#     for _ in range(n_episodes):\n",
        "#         obs, _ = env.reset()\n",
        "#         terminated = False\n",
        "#         truncated = False\n",
        "#         steps = 0\n",
        "\n",
        "#         while not (terminated or truncated):\n",
        "#             action, _ = model.predict(obs, deterministic=True)\n",
        "#             obs, reward, terminated, truncated, _ = env.step(action)\n",
        "#             steps += 1\n",
        "\n",
        "#             if terminated:\n",
        "#                 success_count += 1\n",
        "\n",
        "#         episode_lengths.append(steps)\n",
        "\n",
        "#     success_rate = success_count / n_episodes\n",
        "#     avg_length = np.mean(episode_lengths)\n",
        "#     return success_rate, avg_length\n",
        "\n",
        "def evaluate_model(model, env, n_episodes=EVAL_EPISODES):\n",
        "    success_count = 0\n",
        "    episode_lengths = []\n",
        "\n",
        "    for _ in range(n_episodes):\n",
        "        obs, _ = env.reset()\n",
        "        total_reward = 0\n",
        "        steps = 0\n",
        "\n",
        "        while True:\n",
        "            action, _ = model.predict(obs, deterministic=True)\n",
        "            obs, reward, terminated, truncated, _ = env.step(action)\n",
        "            steps += 1\n",
        "            total_reward += reward\n",
        "\n",
        "            if terminated or truncated:\n",
        "                if terminated:\n",
        "                    success_count += 1\n",
        "                episode_lengths.append(steps)\n",
        "                break\n",
        "\n",
        "    success_rate = success_count / n_episodes\n",
        "    avg_length = np.mean(episode_lengths)\n",
        "    return success_rate, avg_length\n",
        "\n",
        "def plot_learning_curves(ppo_rewards, dqn_rewards, ppo_lengths, dqn_lengths):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(ppo_rewards, label='PPO')\n",
        "    plt.plot(dqn_rewards, label='DQN')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Episode Reward')\n",
        "    plt.title('Training Reward Progress')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(ppo_lengths, label='PPO')\n",
        "    plt.plot(dqn_lengths, label='DQN')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Episode Length')\n",
        "    plt.title('Training Episode Length Progress')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def visualize_agent(model, env):\n",
        "    obs, _ = env.reset()\n",
        "    terminated = False\n",
        "    truncated = False\n",
        "    path = [obs.copy()]\n",
        "\n",
        "    print(\"Agent's path:\")\n",
        "    # env.render()\n",
        "\n",
        "    while not (terminated or truncated):\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        obs, _, terminated, truncated, _ = env.step(action)\n",
        "        path.append(obs.copy())\n",
        "        # env.render()\n",
        "\n",
        "    print(f\"Final path coordinates: {path}\")\n",
        "\n",
        "env = YourAwesomeEnvironment()\n",
        "\n",
        "print(\"Training PPO...\")\n",
        "ppo_model, ppo_rewards, ppo_lengths = train_model(PPO, env)\n",
        "\n",
        "print(\"\\nTraining DQN...\")\n",
        "dqn_model, dqn_rewards, dqn_lengths = train_model(DQN, env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjkzmYf_humq"
      },
      "source": [
        "📊 Algorithm Comparison\n",
        "Compare RL algorithms (e.g., PPO, DQN) based on:\n",
        "- Total reward over time\n",
        "- Sample efficiency\n",
        "- Hyperparameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SmWitNGTDWz"
      },
      "outputs": [],
      "source": [
        "ppo_success, ppo_avg_length = evaluate_model(ppo_model, env)\n",
        "dqn_success, dqn_avg_length = evaluate_model(dqn_model, env)\n",
        "\n",
        "plot_learning_curves(ppo_rewards, dqn_rewards, ppo_lengths, dqn_lengths)\n",
        "\n",
        "print(\"\\nPerformance Metrics:\")\n",
        "print(f\"PPO Success Rate: {ppo_success:.2%}\")\n",
        "print(f\"DQN Success Rate: {dqn_success:.2%}\")\n",
        "print(f\"\\nPPO Average Episode Length: {ppo_avg_length:.2f} steps\")\n",
        "print(f\"DQN Average Episode Length: {dqn_avg_length:.2f} steps\")\n",
        "\n",
        "print(\"\\nVisualizing PPO agent:\")\n",
        "visualize_agent(ppo_model, env)\n",
        "\n",
        "print(\"\\nVisualizing DQN agent:\")\n",
        "visualize_agent(dqn_model, env)\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US_xeiGc9hYA"
      },
      "source": [
        "# **Task 3: Pygame 🎮 Tutorial & Custom RL Environment (Bonus)**\n",
        "\n",
        "In this bonus task, you will implement a custom RL environment using Pygame and make it Gym-compatible for training an RL agent. Pygame is widely used for 2D game development and can be an excellent tool for creating custom RL environments. You will start by learning basic Pygame concepts (game loop, rendering, input handling), then implement a simple grid-based environment where an agent moves toward a goal while avoiding obstacles. Finally, you will train an RL agent using Stable-Baselines3 (SB3) to solve the environment. If you’re looking for inspiration, consider recreating the Chrome Dino game 🦖 as an RL environment which will be introduced at workshop or future TA sessions, but feel free to explore your own ideas!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJQTmN6Q56lu"
      },
      "source": [
        "![preview.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAzGwDFc56Bv"
      },
      "outputs": [],
      "source": [
        "import pygame\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "GRID_SIZE = 5\n",
        "CELL_SIZE = 60\n",
        "SCREEN_SIZE = GRID_SIZE * CELL_SIZE\n",
        "WHITE = (255, 255, 255)\n",
        "BLACK = (0, 0, 0)\n",
        "GREEN = (0, 255, 0)\n",
        "RED = (255, 0, 0)\n",
        "BLUE = (0, 0, 255)\n",
        "\n",
        "class GridWorldEnv(gym.Env):\n",
        "    metadata = {'render.modes': ['human', 'rgb_array']}\n",
        "\n",
        "    def __init__(self):\n",
        "        super(GridWorldEnv, self).__init__()\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0, high=GRID_SIZE-1, shape=(4,), dtype=np.int32\n",
        "        )\n",
        "\n",
        "        pygame.init()\n",
        "        self.screen = pygame.display.set_mode((SCREEN_SIZE, SCREEN_SIZE))\n",
        "        self.clock = pygame.time.Clock()\n",
        "\n",
        "        self.agent_pos = None\n",
        "        self.goal_pos = None\n",
        "        self.obstacles = []\n",
        "        self.max_steps = 100\n",
        "        self.current_step = 0\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.agent_pos = np.array([0, 0])\n",
        "        self.goal_pos = np.array([GRID_SIZE-1, GRID_SIZE-1])\n",
        "        self.obstacles = [(2, 1), (1, 3), (3, 2)]\n",
        "        self.current_step = 0\n",
        "        return self._get_obs(), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        self.current_step += 1\n",
        "        new_pos = np.copy(self.agent_pos)\n",
        "\n",
        "        if action == 0:\n",
        "            new_pos[0] = max(0, new_pos[0] - 1)\n",
        "        elif action == 1:\n",
        "            new_pos[0] = min(GRID_SIZE-1, new_pos[0] + 1)\n",
        "        elif action == 2:\n",
        "            new_pos[1] = max(0, new_pos[1] - 1)\n",
        "        elif action == 3:\n",
        "            new_pos[1] = min(GRID_SIZE-1, new_pos[1] + 1)\n",
        "\n",
        "        terminated = False\n",
        "        truncated = False\n",
        "        reward = -0.1\n",
        "\n",
        "        if tuple(new_pos) in self.obstacles:\n",
        "            reward = -10\n",
        "            terminated = True\n",
        "        else:\n",
        "            self.agent_pos = new_pos\n",
        "\n",
        "        if np.array_equal(self.agent_pos, self.goal_pos):\n",
        "            reward = 10\n",
        "            terminated = True\n",
        "\n",
        "        if self.current_step >= self.max_steps:\n",
        "            truncated = True\n",
        "\n",
        "        return self._get_obs(), reward, terminated, truncated, {}\n",
        "\n",
        "    def _get_obs(self):\n",
        "        return np.concatenate((self.agent_pos, self.goal_pos))\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        self.screen.fill(WHITE)\n",
        "\n",
        "        for x in range(GRID_SIZE):\n",
        "            for y in range(GRID_SIZE):\n",
        "                rect = pygame.Rect(y*CELL_SIZE, x*CELL_SIZE, CELL_SIZE, CELL_SIZE)\n",
        "                pygame.draw.rect(self.screen, BLACK, rect, 1)\n",
        "\n",
        "        pygame.draw.circle(self.screen, BLUE,\n",
        "                          (int((self.agent_pos[1]+0.5)*CELL_SIZE),\n",
        "                          int((self.agent_pos[0]+0.5)*CELL_SIZE)),\n",
        "                          CELL_SIZE//3)\n",
        "\n",
        "        pygame.draw.rect(self.screen, GREEN,\n",
        "                        (self.goal_pos[1]*CELL_SIZE, self.goal_pos[0]*CELL_SIZE,\n",
        "                         CELL_SIZE, CELL_SIZE))\n",
        "\n",
        "        for obs in self.obstacles:\n",
        "            pygame.draw.rect(self.screen, RED,\n",
        "                            (obs[1]*CELL_SIZE, obs[0]*CELL_SIZE,\n",
        "                             CELL_SIZE, CELL_SIZE))\n",
        "\n",
        "        if mode == 'human':\n",
        "            pygame.display.flip()\n",
        "            self.clock.tick(10)\n",
        "        elif mode == 'rgb_array':\n",
        "            return pygame.surfarray.array3d(self.screen)\n",
        "\n",
        "    def close(self):\n",
        "        pygame.quit()\n",
        "\n",
        "\n",
        "class TrainingCallback(BaseCallback):\n",
        "    def __init__(self, check_freq=1000):\n",
        "        super().__init__()\n",
        "        self.check_freq = check_freq\n",
        "        self.successes = []\n",
        "\n",
        "    def _on_step(self):\n",
        "        if self.n_calls % self.check_freq == 0:\n",
        "            success_rate = self._evaluate()\n",
        "            self.successes.append(success_rate)\n",
        "            print(f\"Step: {self.num_timesteps}, Success Rate: {success_rate:.2f}\")\n",
        "        return True\n",
        "\n",
        "    def _evaluate(self, n_episodes=10):\n",
        "        env = self.training_env.envs[0]\n",
        "        successes = 0\n",
        "\n",
        "        for _ in range(n_episodes):\n",
        "            obs = env.reset()\n",
        "            done = False\n",
        "            while not done:\n",
        "                action, _ = self.model.predict(obs)\n",
        "                obs, _, done, _ = env.step(action)\n",
        "                if np.array_equal(obs[:2], obs[2:]):\n",
        "                    successes += 1\n",
        "                    break\n",
        "        return successes / n_episodes\n",
        "\n",
        "\n",
        "TOTAL_TIMESTEPS = 100_000\n",
        "\n",
        "env = DummyVecEnv([lambda: GridWorldEnv()])\n",
        "\n",
        "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
        "           learning_rate=3e-4,\n",
        "           n_steps=2048,\n",
        "           batch_size=64,\n",
        "           gamma=0.99)\n",
        "\n",
        "callback = TrainingCallback()\n",
        "model.learn(total_timesteps=TOTAL_TIMESTEPS, callback=callback)\n",
        "\n",
        "plt.plot(callback.successes)\n",
        "plt.xlabel(\"Evaluation Points\")\n",
        "plt.ylabel(\"Success Rate\")\n",
        "plt.title(\"Training Progress\")\n",
        "plt.show()\n",
        "\n",
        "model.save(\"gridworld_ppo\")\n",
        "\n",
        "obs = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    action, _ = model.predict(obs)\n",
        "    obs, _, done, _ = env.step(action)\n",
        "    env.render()\n",
        "    pygame.time.wait(200)\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cxQ4XG7blixc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}